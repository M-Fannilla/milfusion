{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from google.cloud import vision\n",
    "from google.cloud import storage\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"fannilla-dev.json\""
   ],
   "id": "5526c0f167f73e73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "vision_client = vision.ImageAnnotatorClient()\n",
    "storage_client = storage.Client()\n",
    "\n",
    "BUCKET_NAME = 'chum_bucket_stuff'\n",
    "\n",
    "BUCKET = storage_client.bucket(BUCKET_NAME)\n",
    "SRC_DIR = Path(\"/Volumes/external_drive\")\n",
    "TEMP_DIR = Path(\"./temp\")\n",
    "TEMP_DIR.mkdir(exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('datasets/images_high_res_dataset.csv')\n",
    "df.sort_values(by=['gallery_category', 'gallery_name'], inplace=True)"
   ],
   "id": "feff1ae3c9717a13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df['blobs'] = SRC_DIR / df.gallery_category / df.gallery_name / df.filename\n",
    "df['blobs'] = TEMP_DIR / df.gallery_category / df.gallery_name / df.filename\n",
    "all_blobs = df['blobs'].tolist()"
   ],
   "id": "b89207163b75097",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def download_blob(filepath: Path) -> Path:\n",
    "    _bucket_file_path = filepath.as_posix().replace(TEMP_DIR.as_posix(), \"pics\")\n",
    "    blob = BUCKET.blob(_bucket_file_path)\n",
    "    B = Path(_bucket_file_path.replace(\"pics\", \"temp\"))\n",
    "    B.parent.mkdir(parents=True, exist_ok=True)\n",
    "    blob.download_to_filename(B)\n",
    "    return B\n",
    "\n",
    "\n",
    "def request_ocr(blob_location: str) -> vision.AnnotateImageResponse:\n",
    "    image = vision.Image()\n",
    "    image.source.image_uri = blob_location\n",
    "    request = {\n",
    "        \"image\": image,\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type_\": vision.Feature.Type.TEXT_DETECTION\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    return vision_client.annotate_image(request)\n",
    "\n",
    "\n",
    "def convert_string_to_vertices_list(vertices_string):\n",
    "    pattern = re.compile(r'x:\\s*(\\d+)\\s*y:\\s*(\\d+)')\n",
    "    matches = pattern.findall(vertices_string)\n",
    "    return [{'x': int(x), 'y': int(y)} for x, y in matches]\n",
    "\n",
    "\n",
    "def get_vertices_from_response(response: vision.AnnotateImageResponse):\n",
    "    if not response.text_annotations:\n",
    "        return None\n",
    "\n",
    "    bounding_poly = response.text_annotations[0].bounding_poly\n",
    "    vertices = str(bounding_poly.vertices)\n",
    "\n",
    "    return convert_string_to_vertices_list(vertices)\n",
    "\n",
    "\n",
    "def crop_image(local_image_path: Path, vertices: list) -> Path | None:\n",
    "    try:\n",
    "        y_vertices = [int(vertex['y']) for vertex in vertices]\n",
    "        upper = min(y_vertices)\n",
    "        lower = max(y_vertices)\n",
    "\n",
    "        image = Image.open(local_image_path)\n",
    "        width, height = image.size\n",
    "\n",
    "        if abs(lower - upper) > 0.25 * height:\n",
    "            return\n",
    "\n",
    "        if upper < height / 2:\n",
    "            cropped_image = image.crop(\n",
    "                (0, lower, width, height)  # (left, upper, right, and lower)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            cropped_image = image.crop(\n",
    "                (0, 0, width, upper)  # (left, upper, right, and lower)\n",
    "            )\n",
    "\n",
    "        local_image_path = Path(local_image_path).parent / \"cropped\" / Path(local_image_path).name\n",
    "        local_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cropped_image.save(local_image_path)\n",
    "        return local_image_path\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_file_to_storage(local_file_path: str, gcp_file_path: str):\n",
    "    _blob = BUCKET.blob(gcp_file_path)\n",
    "    _blob.upload_from_filename(local_file_path)\n",
    "\n",
    "\n",
    "def main_process(blob_name: Path):\n",
    "    cropped_file_path = blob_name.parent / 'cropped' / blob_name.name\n",
    "    vertices_path = cropped_file_path.parent / f\"{cropped_file_path.with_suffix('').name}.json\"\n",
    "    cropped_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if vertices_path.exists():\n",
    "        with open(vertices_path, 'r') as json_file:\n",
    "            vertices = json.load(json_file)\n",
    "    else:\n",
    "        gcp_file = f\"gs://{BUCKET_NAME}/pics{blob_name.as_posix().replace(SRC_DIR.as_posix(), '')}\"\n",
    "        response = request_ocr(gcp_file)\n",
    "        vertices = get_vertices_from_response(response)\n",
    "\n",
    "    local_image_path = blob_name\n",
    "    if vertices:  # If OCR found vertices\n",
    "        local_image_path_cropped = crop_image(local_image_path, vertices)\n",
    "\n",
    "        if local_image_path_cropped:  # if image cropping was successful with given vertices\n",
    "            with open(vertices_path, 'w') as json_file:\n",
    "                json.dump(vertices, json_file, indent=4)\n",
    "\n",
    "\n",
    "def get_local_ocr(image_path: str):\n",
    "    ocr_reader = easyocr.Reader(['en'])\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    results = ocr_reader.readtext(gray_image)\n",
    "\n",
    "    vertices = []\n",
    "    for result in results:\n",
    "        formatted_bbox = [{'x': int(point[0]), 'y': int(point[1])} for point in result[0]]\n",
    "        vertices.extend(formatted_bbox)\n",
    "\n",
    "    return vertices, image\n",
    "\n",
    "\n",
    "def crop_and_save_cv2_image(vertices: list, image, local_image_path) -> None:\n",
    "    try:\n",
    "        y_vertices = [int(vertex['y']) for vertex in vertices]\n",
    "        upper = min(y_vertices)\n",
    "        lower = max(y_vertices)\n",
    "\n",
    "        height, width = image.shape[:2]\n",
    "\n",
    "        if abs(lower - upper) > 0.25 * height:\n",
    "            return None\n",
    "\n",
    "        if upper < height / 2:\n",
    "            cropped_image = image[lower:height, 0:width]  # Crop lower part of the image\n",
    "        else:\n",
    "            cropped_image = image[0:upper, 0:width]  # Crop upper part of the image\n",
    "\n",
    "        local_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cv2.imwrite(local_image_path.as_posix(), cropped_image)\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def remote_process(blob_name: Path):\n",
    "    downloaded_image_path = download_blob(blob_name)\n",
    "    cropped_file_path = blob_name.parent / 'cropped' / blob_name.name\n",
    "    vertices_path = cropped_file_path.parent / f\"{cropped_file_path.with_suffix('').name}.json\"\n",
    "    cropped_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # if not vertices_path.exists():  # If OCR found vertices\n",
    "    vertices, image = get_local_ocr(downloaded_image_path)\n",
    "    # crop_and_save_cv2_image(\n",
    "    #     vertices, image, cropped_file_path\n",
    "    # )\n",
    "\n",
    "    if vertices:  # if image cropping was successful with given vertices\n",
    "        with open(vertices_path, 'w') as json_file:\n",
    "            json.dump(vertices, json_file, indent=4)"
   ],
   "id": "64fa7ef4538d4cdb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "blobs = [\n",
    "    b for b in sorted(all_blobs)\n",
    "    if '/amateur/' in b.as_posix()\n",
    "]\n",
    "len(blobs)"
   ],
   "id": "f313de17ad8b8e19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GCP OCR",
   "id": "11d8ab78885e5f43"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pause = 60\n",
    "# futures = []\n",
    "# \n",
    "# with ThreadPoolExecutor(max_workers=16) as executor:\n",
    "#     for i, blob in enumerate(blobs):\n",
    "#         futures.append(executor.submit(main_process, blob))\n",
    "# \n",
    "#         if i != 0 and i % 1700 == 0:\n",
    "#             start = time.time()\n",
    "#             for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing images\"):\n",
    "#                 future.result()\n",
    "# \n",
    "#             while time.time() - start <= pause:\n",
    "#                 time.sleep(2)\n",
    "# \n",
    "#             futures = []"
   ],
   "id": "50f4e7a38bc17b02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cloud processing",
   "id": "57864feb3addf394"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "remote_process(blobs[0])",
   "id": "a3dbb5add06cbf19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_blobs = blobs[:100]\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for blob in tqdm(_blobs, total=len(_blobs), desc=\"Processing images\"):\n",
    "        remote_process(blob)"
   ],
   "id": "2fe55951c2e3ad26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9067c85a9a776aa3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
