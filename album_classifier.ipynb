{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T06:25:34.566878Z",
     "start_time": "2024-06-20T06:25:28.521920Z"
    }
   },
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Tuple\n",
    "from galleries_mapping import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Lambda\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'experimental' from 'tensorflow.keras.mixed_precision' (/Users/milosz.bertman/Projects/milfusion/venv/lib/python3.12/site-packages/keras/_tf_keras/keras/mixed_precision/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclass_weight\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compute_class_weight\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_img, img_to_array\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmixed_precision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental \u001B[38;5;28;01mas\u001B[39;00m mixed_precision\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GlobalAveragePooling2D, Dense, Input, Lambda\n\u001B[1;32m     17\u001B[0m policy \u001B[38;5;241m=\u001B[39m mixed_precision\u001B[38;5;241m.\u001B[39mPolicy(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmixed_float16\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'experimental' from 'tensorflow.keras.mixed_precision' (/Users/milosz.bertman/Projects/milfusion/venv/lib/python3.12/site-packages/keras/_tf_keras/keras/mixed_precision/__init__.py)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# todo: compile dataset with structure - \n",
    "# todo: apply sorting for the df based on available galleries\n",
    "# done: apply gallery mapping"
   ],
   "id": "531eae1f2229b2df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('datasets/galleries_dataset.csv')\n",
    "df.dropna(subset=['categories', 'categories_suggestions'], inplace=True)\n",
    "df['categories'] = df['categories'].apply(ast.literal_eval)\n",
    "df['categories_suggestions'] = df['categories_suggestions'].apply(ast.literal_eval)\n",
    "df.shape"
   ],
   "id": "1b95d74790506b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def merge_categories(row):\n",
    "    categories = set((row['categories']))\n",
    "    categories_suggestions = set(row['categories_suggestions'])\n",
    "    categories_superset = {category.strip().lower() for category in categories.union(categories_suggestions)}\n",
    "    return list(categories_superset)\n",
    "\n",
    "\n",
    "df['labels'] = df['categories'].apply(lambda x: [category.strip().lower() for category in x])\n",
    "df['labels'] = df.apply(merge_categories, axis=1)\n",
    "df.drop(['categories_suggestions', 'categories'], axis=1, inplace=True)\n",
    "df.shape"
   ],
   "id": "281c047015a43e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def gallery_mapping(row):\n",
    "    labels = row.labels\n",
    "\n",
    "    out = []\n",
    "    for L in labels:\n",
    "        _fetched = FIXED_GALLERIES_MAP.get(L, None)\n",
    "        if _fetched is remove_tag:\n",
    "            continue\n",
    "        elif _fetched is remove_gallery:\n",
    "            return None\n",
    "        elif isinstance(_fetched, list):\n",
    "            out.extend(_fetched)\n",
    "        elif _fetched is keep_tag:\n",
    "            out.append(L.lower())\n",
    "\n",
    "    return list(set(out))\n",
    "\n",
    "\n",
    "df['labels'] = df.apply(gallery_mapping, axis=1)\n",
    "df = df[df['labels'].notnull()]\n",
    "df.shape"
   ],
   "id": "676dd9b4bb9e691c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df[['gallery_name', 'labels']]\n",
    "df.head()"
   ],
   "id": "25f0fe3cc37d7c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_labels = mlb.fit_transform(df['labels'])\n",
    "df['one_hot_labels'] = list(one_hot_labels)\n",
    "num_labels = len(mlb.classes_)\n",
    "num_labels"
   ],
   "id": "d5286a4ae4024df1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# CREATE GALLERY MAPPING",
   "id": "72058379762af2ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)",
   "id": "37278a73c78b4eac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_labels = np.concatenate(df['one_hot_labels'].values)\n",
    "class_weights = compute_class_weight('balanced', classes=np.arange(num_labels), y=all_labels)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}"
   ],
   "id": "22cc74240012ced5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_input_shape = (380, 380, 3)\n",
    "max_images = 24\n",
    "image_base_path = 'images'"
   ],
   "id": "b9dd87a53e66306c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_input_shape[:2])\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_gallery(category: tf.Tensor, gallery_name: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    gallery_path = os.path.join(image_base_path, category.numpy().decode('utf-8'), gallery_name.numpy().decode('utf-8'))\n",
    "    image_files = tf.io.gfile.glob(os.path.join(gallery_path, '*.jpg'))[:max_images]\n",
    "    images = tf.data.Dataset.from_tensor_slices(image_files).map(\n",
    "        load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    images = images.batch(max_images)\n",
    "    images = tf.pad(\n",
    "        images,\n",
    "        [\n",
    "            [0, 0],\n",
    "            [0, max_images - tf.shape(images)[0]],\n",
    "            [0, 0],\n",
    "            [0, 0],\n",
    "            [0, 0]\n",
    "        ]\n",
    "    )\n",
    "    images = tf.squeeze(images)\n",
    "    return images, label\n",
    "\n",
    "\n",
    "def tf_process_gallery(category: tf.Tensor, gallery_name: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    return tf.py_function(process_gallery, [category, gallery_name, label], [tf.float32, tf.int64])\n",
    "\n",
    "\n",
    "def create_dataset(df: pd.DataFrame, batch_size: int) -> tf.data.Dataset:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (df['category'].values, df['gallery_name'].values, np.stack(df['one_hot_labels'].values)))\n",
    "    dataset = dataset.map(tf_process_gallery, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset(train_df, batch_size)\n",
    "test_dataset = create_dataset(test_df, batch_size)"
   ],
   "id": "d5408ce91001a085",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_cnn_base() -> Model:\n",
    "    base_model = EfficientNetB4(include_top=False, input_shape=image_input_shape, weights='imagenet')\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_base = create_cnn_base()"
   ],
   "id": "8cece3b1e79cd03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_variable_input(images: tf.Tensor, max_images: int) -> tf.Tensor:\n",
    "    num_images = tf.shape(images)[0]\n",
    "    padded_images = tf.concat([images, tf.zeros([max_images - num_images, *image_input_shape])], axis=0)\n",
    "    # for zero-images duplicate their value\n",
    "    image_features = tf.map_fn(lambda img: cnn_base(img), padded_images, dtype=tf.float32)\n",
    "\n",
    "    mask = tf.sequence_mask([num_images], maxlen=max_images, dtype=tf.float32)\n",
    "    mask = tf.expand_dims(mask, -1)\n",
    "    masked_features = image_features * mask\n",
    "\n",
    "    aggregated_features = tf.reduce_sum(masked_features, axis=0) / tf.reduce_sum(mask, axis=0)\n",
    "    return aggregated_features"
   ],
   "id": "a5486e3e25b01b4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_images = Input(shape=(max_images, *image_input_shape))\n",
    "aggregated_features = Lambda(lambda x: process_variable_input(x, max_images))(input_images)\n",
    "x = Dense(512, activation='relu')(aggregated_features)\n",
    "output = Dense(num_labels, activation='sigmoid')(x)  # num_labels is the number of classes\n",
    "model = Model(inputs=input_images, outputs=output)"
   ],
   "id": "27743595087d19d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def weighted_binary_crossentropy(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    weights = tf.constant(class_weights, dtype=tf.float32)\n",
    "    epsilon = tf.keras.backend.epsilon()\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    bce = y_true * tf.math.log(y_pred + epsilon) + (1 - y_true) * tf.math.log(1 - y_pred + epsilon)\n",
    "    weighted_bce = -bce * weights\n",
    "    return tf.reduce_mean(weighted_bce, axis=-1)"
   ],
   "id": "86b206c1d809c730",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=weighted_binary_crossentropy, metrics=[\n",
    "    tfa.metrics.HammingLoss(mode='multilabel', name='hamming_loss'),\n",
    "    tfa.metrics.F1Score(num_classes=num_labels, average='micro', name='f1_micro'),\n",
    "    tfa.metrics.F1Score(num_classes=num_labels, average='macro', name='f1_macro'),\n",
    "    tfa.metrics.F1Score(num_classes=num_labels, average='weighted', name='f1_weighted')\n",
    "])\n",
    "model.summary()"
   ],
   "id": "9506f8700db3cc57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.fit(train_dataset, epochs=10, validation_data=test_dataset)",
   "id": "5ef7eae691674a39",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
