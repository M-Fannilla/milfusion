{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-480.0.0-linux-x86_64.tar.gz\n",
    "# tar -xf google-cloud-cli-480.0.0-linux-x86_64.tar.gz\n",
    "# ./google-cloud-sdk/install.sh\n",
    "# ./google-cloud-sdk/bin/gcloud init"
   ],
   "id": "885a542e542b1861"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# git clone https://github.com/M-Fannilla/milfusion.git && cd milfusion && pip install -r requirements.txt\n",
    "# !cd /workspace && mkdir images\n",
    "# gsutil -m cp -r \"gs://chum_bucket_stuff/images.zip\" /workspace/images"
   ],
   "id": "c833ea831070d41c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0ffeda9d2aac6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f788ee193b745d6a180625562d16b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42f47b5ceed9a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SRC_DIR\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Callable\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mprompts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprompts\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m simple_reduce_prompt, medium_prompt, full_prompt\n",
      "File \u001B[0;32m~/milfusion/utils.py:4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mshutil\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpathlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcloud\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m vision\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcloud\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m storage\n\u001B[1;32m      7\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGOOGLE_APPLICATION_CREDENTIALS\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mos\u001B[38;5;241m.\u001B[39mgetcwd()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/fannilla-dev.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from utils import SRC_DIR\n",
    "from typing import Callable\n",
    "from prompts.prompts import simple_reduce_prompt, medium_prompt, full_prompt\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b63248f584e218",
   "metadata": {},
   "outputs": [],
   "source": "labels_df = pd.read_csv(SRC_DIR / \"compiled_cropped_medium_one_hot.csv\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384db22eca929b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(\n",
    "    \"lliuhaotian/llava-v1.6-vicuna-7b\"\n",
    ")\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    \"liuhaotian/llava-v1.6-vicuna-7b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7ae9e916a5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_results(answers):\n",
    "    def extract_list(input_string: str):\n",
    "        pattern = r'\\[(.*?)\\]'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        return matches[0].strip().replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "    dirty = [extract_list(ans.split(\"ASSISTANT\")[-1]).split(\",\") for ans in answers]\n",
    "\n",
    "    out = []\n",
    "    for D in dirty:\n",
    "        out.append([x.strip() for x in D])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def batch_loader(dataframe: pd.DataFrame, batch_size: int, dynamic_prompt: Callable = medium_prompt):\n",
    "    for i in range(0, len(dataframe), batch_size):\n",
    "        temp_df = dataframe.iloc[i:i + batch_size]\n",
    "        file_paths = temp_df.file_path.tolist()\n",
    "        labels = temp_df.labels.tolist()\n",
    "\n",
    "        images = [Image.open(SRC_DIR / file_path) for file_path in file_paths]\n",
    "        prompts = [f\"USER: <image>{dynamic_prompt(label)} ASSISTANT:\" for label in labels]\n",
    "        yield file_paths, images, prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f149efd1007a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "result_folder = Path(\"./llava_results\")\n",
    "result_folder.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def get_json_path(batch_number: int):\n",
    "    return result_folder / f\"{batch_number}.json\"\n",
    "\n",
    "\n",
    "def get_last_batch():\n",
    "    return max([\n",
    "        int(x.stem)\n",
    "        for x in result_folder.iterdir()\n",
    "        if x.is_file() and not x.as_posix().endswith(\".json\")\n",
    "    ])\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "last_batch = get_last_batch()\n",
    "\n",
    "for i, (file_paths, images, prompts) in enumerate(batch_loader(labels_df, batch_size)):\n",
    "    if i < last_batch:\n",
    "        continue\n",
    "\n",
    "    inputs = processor(prompts, images=images, return_tensors=\"pt\", padding=True).to(\"cuda:0\")\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "    res = batch_results(processor.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "    result_dict = {\n",
    "        file_path: res[i]\n",
    "        for i, file_path in enumerate(file_paths)\n",
    "    }\n",
    "\n",
    "    json_path = get_json_path(i)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_path, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
