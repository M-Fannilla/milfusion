{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0ffeda9d2aac6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f788ee193b745d6a180625562d16b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install git+https://github.com/huggingface/transformers\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42f47b5ceed9a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SRC_DIR\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_reduce_prompt, medium_prompt, full_prompt\n",
      "File \u001b[0;32m~/milfusion/utils.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vision\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m storage\n\u001b[1;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOOGLE_APPLICATION_CREDENTIALS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetcwd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/fannilla-dev.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from utils import SRC_DIR\n",
    "from typing import Callable\n",
    "from prompts.prompts import simple_reduce_prompt, medium_prompt, full_prompt\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b63248f584e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"datasets/VLM_labels_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9384db22eca929b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LlavaNextProcessor.from_pretrained(\n",
    "    \"lliuhaotian/llava-v1.6-vicuna-7b\"\n",
    ")\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    \"liuhaotian/llava-v1.6-vicuna-7b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "model.to(\"cuda:0\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7ae9e916a5a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_results(answers):\n",
    "    def extract_list(input_string: str):\n",
    "        pattern = r'\\[(.*?)\\]'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        return matches[0].strip().replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "\n",
    "    dirty = [extract_list(ans.split(\"ASSISTANT\")[-1]).split(\",\") for ans in answers]\n",
    "\n",
    "    out = []\n",
    "    for D in dirty:\n",
    "        out.append([x.strip() for x in D])\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "def batch_loader(dataframe: pd.DataFrame, batch_size: int, dynamic_prompt: Callable = medium_prompt):\n",
    "    for i in range(0, len(dataframe), batch_size):\n",
    "        temp_df = dataframe.iloc[i:i + batch_size]\n",
    "        file_paths = temp_df.file_path.tolist()\n",
    "        labels = temp_df.labels.tolist()\n",
    "\n",
    "        images = [Image.open(SRC_DIR / file_path) for file_path in file_paths]\n",
    "        prompts = [f\"USER: <image>{dynamic_prompt(label)} ASSISTANT:\" for label in labels]\n",
    "        yield file_paths, images, prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f149efd1007a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "result_folder = Path(\"./llava_results\")\n",
    "result_folder.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def get_json_path(batch_number: int):\n",
    "    return result_folder / f\"{batch_number}.json\"\n",
    "\n",
    "\n",
    "def get_last_batch():\n",
    "    return max([\n",
    "        int(x.stem)\n",
    "        for x in result_folder.iterdir()\n",
    "        if x.is_file() and not x.as_posix().endswith(\".json\")\n",
    "    ])\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "last_batch = get_last_batch()\n",
    "\n",
    "for i, (file_paths, images, prompts) in enumerate(batch_loader(labels_df, batch_size)):\n",
    "    if i < last_batch:\n",
    "        continue\n",
    "\n",
    "    inputs = processor(prompts, images=images, return_tensors=\"pt\", padding=True).to(\"cuda:0\")\n",
    "    output = model.generate(**inputs, max_new_tokens=100)\n",
    "    res = batch_results(processor.batch_decode(output, skip_special_tokens=True))\n",
    "\n",
    "    result_dict = {\n",
    "        file_path: res[i]\n",
    "        for i, file_path in enumerate(file_paths)\n",
    "    }\n",
    "\n",
    "    json_path = get_json_path(i)\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(json_path, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
