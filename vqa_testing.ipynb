{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# git clone https://github.com/M-Fannilla/milfusion.git && cd milfusion && pip install -r requirements.txt",
   "id": "49a3f355c95bb0ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# cd /workspace\n",
    "# curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-480.0.0-linux-x86_64.tar.gz\n",
    "# tar -xf google-cloud-cli-480.0.0-linux-x86_64.tar.gz\n",
    "# ./google-cloud-sdk/install.sh\n",
    "# ./google-cloud-sdk/bin/gcloud init"
   ],
   "id": "885a542e542b1861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# cd /workspace && mkdir images\n",
    "# gsutil -m cp \"gs://chum_bucket_stuff/images.zip.partaa\" \"gs://chum_bucket_stuff/images.zip.partab\" \"gs://chum_bucket_stuff/images.zip.partac\" \"gs://chum_bucket_stuff/images.zip.partad\" \"gs://chum_bucket_stuff/images.zip.partae\" \"gs://chum_bucket_stuff/images.zip.partaf\" /workspace\n",
    "# apt update && apt install unzip\n",
    "# cat images.zip.part* > images.zip\n",
    "# cd images && unzip -q images.zip"
   ],
   "id": "c833ea831070d41c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# huggingface-cli download llava-hf/llava-v1.6-vicuna-7b-hf\n",
    "# huggingface-cli download llava-hf/llava-v1.6-mistral-7b-hf\n",
    "# huggingface-cli download llava-hf/llava-v1.6-vicuna-13b-hf\n",
    "# huggingface-cli download OpenGVLab/Mini-InternVL-Chat-4B-V1-5"
   ],
   "id": "899d994b9637f36",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a42f47b5ceed9a61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T16:19:16.750347Z",
     "start_time": "2024-06-16T16:19:16.032573Z"
    }
   },
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import SRC_DIR\n",
    "from typing import Callable\n",
    "from prompts.prompts import *\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "\n",
    "labels_df = pd.read_csv(\"datasets/cropped_all_one_hot.csv\", index_col = 0)\n",
    "labels_df.drop(['good_image'], axis = 1, inplace = True)\n",
    "torch.cuda.empty_cache()\n",
    "labels_df.shape"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9384db22eca929b4",
   "metadata": {},
   "source": [
    "model_name = \"llava-hf/llava-v1.6-mistral-7b-hf\"\n",
    "# model_name = \"llava-hf/llava-v1.6-vicuna-7b-hf\"\n",
    "# model_name = \"llava-hf/llava-v1.6-vicuna-13b-hf\"\n",
    "# model_name = \"OpenGVLab/Mini-InternVL-Chat-4B-V1-5\"\n",
    "\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(\n",
    "    model_name, padding_side='left'\n",
    ")\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    model_name, torch_dtype=torch.float16, low_cpu_mem_usage=True\n",
    ").to(\"cuda\").eval()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9db7ae9e916a5a4f",
   "metadata": {},
   "source": [
    "def batch_results(answers):\n",
    "    def extract_list(input_string: str):\n",
    "        input_string = input_string.replace(\"\\n\", \"\")\n",
    "        pattern = r'\\[(.*?)\\]'\n",
    "        matches = re.findall(pattern, input_string)\n",
    "        if len(matches) > 0:\n",
    "            matches_list = matches[0].strip().replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")\n",
    "            return [m.strip() for m in matches_list]  # proper list return\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    dirty = [extract_list(ans.split(\"ASSISTANT\")[-1]) for ans in answers]\n",
    "    out = []\n",
    "    for D in dirty:\n",
    "        out.append([x.strip() for x in D])\n",
    "    return out\n",
    "\n",
    "\n",
    "def batch_loader(dataframe: pd.DataFrame, batch_size: int, dynamic_prompt: Callable):\n",
    "    for i in range(0, len(dataframe), batch_size):\n",
    "        temp_df = dataframe.iloc[i:i + batch_size]\n",
    "        file_paths = temp_df.file_path.tolist()\n",
    "        labels = temp_df.labels.tolist()\n",
    "\n",
    "        images = [Image.open(SRC_DIR / file_path) for file_path in file_paths]\n",
    "        prompts = [f\"USER: <image>{dynamic_prompt(label)} ASSISTANT:\" for label in labels]\n",
    "        yield file_paths, images, prompts"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f149efd1007a90a",
   "metadata": {},
   "source": [
    "result_folder = Path(\"./llava_results\")\n",
    "result_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "def get_json_path(batch_number: int, prompt: Callable):\n",
    "    _p = result_folder / prompt.__name__ / f\"{batch_number}.json\"\n",
    "    _p.parent.mkdir(exist_ok=True, parents=True)\n",
    "    return _p\n",
    "\n",
    "\n",
    "def get_last_batch():\n",
    "    return max(\n",
    "        [\n",
    "            int(x.stem)\n",
    "            for x in result_folder.iterdir()\n",
    "            if x.is_file() and not x.as_posix().endswith(\".json\")\n",
    "        ] + [0]\n",
    "    )\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "prompts = [\n",
    "    simple_original, simple_0, simple_1, simple_2, simple_3, simple_4,\n",
    "    medium_original, medium_0, medium_1, medium_2, medium_3, medium_4,\n",
    "    chat_original, chat_0, chat_1, chat_2, chat_3, chat_4\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for P in tqdm(prompts, total=len(prompts), desc=\"Batching prompts...\"):\n",
    "    for i, (file_paths, images, prompts) in enumerate(batch_loader(labels_df[:batch_size * 4], batch_size, P)):\n",
    "        inputs = processor(prompts, images=images, return_tensors=\"pt\", padding=True).to(\"cuda:0\")\n",
    "        output = model.generate(**inputs, max_new_tokens=100)\n",
    "        result = processor.batch_decode(output, skip_special_tokens=True)\n",
    "        res = batch_results(result)\n",
    "\n",
    "        result_dict = {\n",
    "            file_path: res[i]\n",
    "            for i, file_path in enumerate(file_paths)\n",
    "        }\n",
    "\n",
    "        json_path = get_json_path(i, P)\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(result_dict, f)\n",
    "\n",
    "print(f\"{model_name} took {(time.time() - start) / 60}mins to complete\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "result_folder = Path(\"./llava_results_mistral\")\n",
    "\n",
    "\n",
    "def get_json_path(batch_number: int, prompt: Callable):\n",
    "    _p = result_folder / prompt.__name__ / f\"{batch_number}.json\"\n",
    "    _p.parent.mkdir(exist_ok=True, parents=True)\n",
    "    return _p\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    simple_original, simple_0, simple_1, simple_2, simple_3, simple_4,\n",
    "    medium_original, medium_0, medium_1, medium_2, medium_3, medium_4,\n",
    "    chat_original, chat_0, chat_1, chat_2, chat_3, chat_4\n",
    "]\n",
    "\n",
    "\n",
    "def plot_images_with_labels(version: int, prompt_list: List[Callable]):\n",
    "    image_paths = None\n",
    "    all_labels = {}\n",
    "\n",
    "    for P in prompt_list:\n",
    "        with open(get_json_path(version, P), 'r') as f:\n",
    "            data_simple = json.load(f)\n",
    "        all_labels[P.__name__] = list(data_simple.values())  # Use the name of the function as the key\n",
    "        if image_paths is None:\n",
    "            image_paths = list(data_simple.keys())\n",
    "\n",
    "    num_images = len(image_paths)\n",
    "    num_columns = 1\n",
    "    num_rows = num_images\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(10, num_rows * 5))\n",
    "\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = plt.imread(f\"./images/{img_path}\")\n",
    "        axes[i].imshow(img)\n",
    "\n",
    "        _title = \"\"\n",
    "        for fn_name, labels in all_labels.items():\n",
    "            _T = f\"{fn_name}: {labels[i]}\\n\"\n",
    "            _title += _T\n",
    "\n",
    "        axes[i].set_title(_title, fontsize=10)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out_path = result_folder / f\"prompt_results_{version}.jpg\"\n",
    "    out_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    plt.savefig(out_path)"
   ],
   "id": "2be006dc5699cb5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for x in range(4):\n",
    "    plot_images_with_labels(version=x, prompt_list=prompts)"
   ],
   "id": "d0068c367855f2d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "answers_list = [\n",
    "    [simple_0, simple_1, medium_1],\n",
    "\n",
    "]"
   ],
   "id": "4b9d25c4277fe9f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inspect the width and height of the cropped images\n",
    "# remove the ones below 500x500 / 600x600"
   ],
   "id": "cd376b9f5de4f98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tag_fixes = {\n",
    "\n",
    "}"
   ],
   "id": "5b4ba66ec08d98d8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
