{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T12:08:02.860718Z",
     "start_time": "2024-06-10T12:08:01.551012Z"
    }
   },
   "source": [
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils import BUCKET\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SRC_DIR = Path('/Volumes/external_drive')"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:08:02.868581Z",
     "start_time": "2024-06-10T12:08:02.863279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_gallery_info(filepath: Path):\n",
    "    filenames = []\n",
    "    for f in os.listdir(filepath.parent):\n",
    "        if not f.startswith(\".\") and not f.endswith(\".txt\"):\n",
    "            filenames.append(f)\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.readlines()\n",
    "\n",
    "    info = {}\n",
    "    spl = filepath.as_posix().split(\"/\")\n",
    "    info['gallery_category'] = spl[3]\n",
    "    info['gallery_name'] = spl[4]\n",
    "\n",
    "    if 'cropped' in filenames:\n",
    "        filenames.remove('cropped')\n",
    "\n",
    "    info['filenames'] = filenames\n",
    "\n",
    "    for line in content:\n",
    "        key = line.split(\":\")[0].strip()\n",
    "        value = line.split(\":\")[-1].strip()\n",
    "        info[key.lower()] = value.replace(\" Pics\", \"\")\n",
    "\n",
    "    return info"
   ],
   "id": "f9bd581a52cba412",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:08:02.937891Z",
     "start_time": "2024-06-10T12:08:02.935890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_gallery(category_name: str, gallery: str):\n",
    "    gallery_info_path = SRC_DIR / category_name / gallery / 'gallery_info.txt'\n",
    "    if gallery_info_path.exists():\n",
    "        gallery_info = parse_gallery_info(gallery_info_path)\n",
    "        return gallery_info"
   ],
   "id": "f44491fada2060bd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:08:03.471118Z",
     "start_time": "2024-06-10T12:08:03.468379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_category(category_name: str):\n",
    "    category_path = SRC_DIR / category_name\n",
    "    category_galleries = [\n",
    "        gallery\n",
    "        for gallery in os.listdir(category_path)\n",
    "        if (category_path / gallery).is_dir()\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        future_to_gallery = [\n",
    "            executor.submit(process_gallery, category_name, gallery)\n",
    "            for gallery in category_galleries\n",
    "        ]\n",
    "\n",
    "        for future in tqdm(\n",
    "                concurrent.futures.as_completed(future_to_gallery),\n",
    "                total=len(future_to_gallery),\n",
    "                desc=f\"Processing {category_name}\",\n",
    "                unit=\"gallery\"\n",
    "        ):\n",
    "            gallery_info = future.result()\n",
    "            if gallery_info:\n",
    "                results.append(gallery_info)\n",
    "\n",
    "    return results"
   ],
   "id": "f2414508c8b9e7da",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:08:03.925206Z",
     "start_time": "2024-06-10T12:08:03.922779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def crawl_images_folder():\n",
    "    categories = [\n",
    "        category for category in os.listdir(SRC_DIR)\n",
    "        if (SRC_DIR / category).is_dir() and not category.startswith(\".\")\n",
    "    ]\n",
    "\n",
    "    all_galleries_info = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_category = [\n",
    "            executor.submit(process_category, category)\n",
    "            for category in categories\n",
    "        ]\n",
    "        for future in tqdm(\n",
    "                concurrent.futures.as_completed(future_to_category),\n",
    "                total=len(future_to_category),\n",
    "                desc=\"Processing categories\", unit=\"category\"\n",
    "        ):\n",
    "            category_galleries_info = future.result()\n",
    "            all_galleries_info.extend(category_galleries_info)\n",
    "\n",
    "    return all_galleries_info"
   ],
   "id": "76e69a8a11f4a80f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    raise FileNotFoundError\n",
    "    df = pd.read_csv('datasets/galleries_dataset.csv')\n",
    "    df = df[df['categories'].notnull() & df['categories'].apply(lambda x: x != [])]\n",
    "    df = df[df['categories_suggestions'].notnull() & df['categories_suggestions'].apply(lambda x: x != [])]\n",
    "    df['filenames'] = df['filenames'].apply(ast.literal_eval)\n",
    "    df['categories'] = df['categories'].apply(ast.literal_eval)\n",
    "    df['categories_suggestions'] = df['categories_suggestions'].apply(ast.literal_eval)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    all_galleries_info = crawl_images_folder()\n",
    "    df = pd.DataFrame(all_galleries_info)\n",
    "    df.drop(['stats', 'tags list'], axis=1, inplace=True)\n",
    "    non_dupes = df.drop_duplicates(subset=['gallery_name'])\n",
    "    _to_delete = df[~df.index.isin(non_dupes.index)]\n",
    "\n",
    "df.shape, _to_delete.shape"
   ],
   "id": "eb4e3a71e20d3cee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if _to_delete.shape[0] > 0:\n",
    "    for _, row in tqdm(\n",
    "            _to_delete.iterrows(),\n",
    "            total=_to_delete.shape[0],\n",
    "            desc=\"Deleting galleries\",\n",
    "            unit=\"gallery\"\n",
    "    ):\n",
    "        category = row['gallery_category']\n",
    "        gallery_name = row['gallery_name']\n",
    "        gallery_path = SRC_DIR / category / gallery_name\n",
    "        if not gallery_path.exists():\n",
    "            continue\n",
    "        print(f\"Deleting {gallery_path}\")\n",
    "        shutil.rmtree(gallery_path)\n",
    "        print(\"Deleted!\")\n",
    "        if BUCKET.blob(f\"pics/{category}/{gallery_name}\").exists():\n",
    "            BUCKET.blob(f\"pics/{category}/{gallery_name}\").delete()"
   ],
   "id": "39d48c179b21ee1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# High Res filtering DATAFRAME",
   "id": "7a94c44e4bb8d627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def process_filenames_to_mini_df(row):\n",
    "    category = row['gallery_category']\n",
    "    gallery_name = row['gallery_name']\n",
    "    filenames = row['filenames']\n",
    "\n",
    "    gallery_dicts = []\n",
    "\n",
    "    def _process_image(category: str, gallery_name: str, filename: str) -> None:\n",
    "        file_path = os.path.join(SRC_DIR, category, gallery_name, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                height, width = img.size\n",
    "                new_row = row.to_dict()\n",
    "                new_row['filename'] = filename\n",
    "                new_row['width'] = width\n",
    "                new_row['height'] = height\n",
    "                gallery_dicts.append(new_row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}. \\nError {e}\")\n",
    "            os.remove(file_path)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(_process_image, category, gallery_name, filename) for filename in filenames\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            future.result()\n",
    "\n",
    "    return pd.DataFrame(gallery_dicts)"
   ],
   "id": "bf7a4b75bf7f7745",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.iloc[1]",
   "id": "95d8eb7f403b0ed0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "process_filenames_to_mini_df(df.iloc[1])",
   "id": "2965a7f826281f89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "futures = []\n",
    "\n",
    "mini_dfs = []\n",
    "for _, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing galleries\", unit=\"gallery\"):\n",
    "    mini_dfs.append(process_filenames_to_mini_df(row))"
   ],
   "id": "efd401bb89ca5a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_df = pd.concat(mini_dfs)\n",
    "enhanced_df['resolution'] = enhanced_df['width'] * enhanced_df['height']\n",
    "enhanced_df = enhanced_df[enhanced_df['resolution'] > 500 * 500]\n",
    "enhanced_df.shape"
   ],
   "id": "f311b71060a11d3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.scatter(enhanced_df['width'], enhanced_df['height'], alpha=0.5, edgecolors='w', linewidth=0.5)\n",
    "plt.title('Distribution of Image Sizes')\n",
    "plt.xlabel('Width')\n",
    "plt.ylabel('Height')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f644931262f88fd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# enhanced_df.drop(['filenames', 'channel', 'tags', 'resolution'], axis=1, inplace=True)\n",
    "enhanced_df = enhanced_df[\n",
    "    enhanced_df['categories'].notnull()\n",
    "    & enhanced_df['categories'].apply(lambda x: x != [])\n",
    "    ]\n",
    "enhanced_df = enhanced_df[\n",
    "    enhanced_df['categories_suggestions'].notnull()\n",
    "    & enhanced_df['categories_suggestions'].apply(lambda x: x != [])\n",
    "    ]\n",
    "enhanced_df.shape\n"
   ],
   "id": "38c6dcece80a5567",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "enhanced_df.to_csv('datasets/images_high_res_dataset.csv', index=False)",
   "id": "44fa07adb1715d6d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
