{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-02T09:05:07.797757Z",
     "start_time": "2024-06-02T09:05:07.499449Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import concurrent.futures\n",
    "\n",
    "SRC_DIR = Path('/Volumes/external_drive')\n",
    "ACRONYMS = ['69', 'BBC', 'BBW', 'BDSM', 'CFNM', 'DP', 'GILF', 'MILF', 'PAWG', 'POV']"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_string(input_string):\n",
    "    word_list = re.findall('[A-Z][^A-Z]*', input_string)\n",
    "\n",
    "    joined_words = []\n",
    "    temp_word = \"\"\n",
    "    for word in word_list:\n",
    "        if word.endswith(\" \"):\n",
    "            temp_word += word\n",
    "        else:\n",
    "            if temp_word:\n",
    "                joined_words.append(temp_word + word)\n",
    "                temp_word = \"\"\n",
    "            else:\n",
    "                joined_words.append(word)\n",
    "\n",
    "    final_words = []\n",
    "    temp_word = \"\"\n",
    "    for word in joined_words:\n",
    "        if len(word) == 1 and word.isupper():\n",
    "            temp_word += word\n",
    "        elif len(word) > 1 and word[1] == \" \":\n",
    "            temp_word += word\n",
    "        elif len(word) > 1 and word[-2] == \" \":\n",
    "            final_words.append(temp_word)\n",
    "            temp_word = \"\"\n",
    "            temp_word += word\n",
    "\n",
    "        else:\n",
    "            if temp_word:\n",
    "                final_words.append(temp_word)\n",
    "                temp_word = \"\"\n",
    "            final_words.append(word)\n",
    "    if temp_word:\n",
    "        final_words.append(temp_word)\n",
    "\n",
    "    word_list = [w for w in final_words if w != \"\"]\n",
    "\n",
    "    new_list = []\n",
    "    for word in word_list:\n",
    "        match = re.match(r\"([a-zA-Z]+)([0-9]+)\", word)\n",
    "        if match:\n",
    "            new_list.append(match.group(1))\n",
    "            new_list.append(int(match.group(2)))\n",
    "        else:\n",
    "            new_list.append(word)\n",
    "    return new_list\n",
    "\n",
    "\n",
    "def split_and_verify_acronyms(words_list, acronyms):\n",
    "    out = []\n",
    "\n",
    "    for word in words_list:\n",
    "        word = str(word)\n",
    "        if word.isupper():\n",
    "            for acronym in acronyms:\n",
    "                if acronym in word:\n",
    "                    out.append(acronym)\n",
    "                    word = word.replace(acronym, \"\")\n",
    "        out.append(word)\n",
    "\n",
    "    return [w for w in out if w != \"\"]\n",
    "\n",
    "\n",
    "def split_and_unify_tags(tags_list: list[str]):\n",
    "    out = []\n",
    "    acronyms = []\n",
    "    for tag in tags_list:\n",
    "        for acronym in ACRONYMS:\n",
    "            if acronym in tag:\n",
    "                tag = tag.replace(acronym, \"\").strip()\n",
    "                if acronym not in acronyms:\n",
    "                    acronyms.append(acronym)\n",
    "        out.append(tag)\n",
    "\n",
    "    result = list(set(out + acronyms))\n",
    "    for tag in result:\n",
    "        if tag in out:\n",
    "            for other_tag in out:\n",
    "                if tag in other_tag and tag != other_tag:\n",
    "                    result.remove(tag)\n",
    "                    break\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_line(line_string: str) -> list[str]:\n",
    "    words_list = process_string(line_string)\n",
    "    words_list = split_and_verify_acronyms(words_list, ACRONYMS)\n",
    "    return [word.replace(\"  \", \" \").strip() for word in words_list]"
   ],
   "id": "5debcc18da3e2325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_gallery_info(filepath: Path):\n",
    "    # Get all the filenames as list\n",
    "    filenames = []\n",
    "    for f in os.listdir(filepath.parent):\n",
    "        if not f.startswith(\".\") and not f.endswith(\".txt\"):\n",
    "            filenames.append(f)\n",
    "\n",
    "    with open(filepath, 'r') as file:\n",
    "        content = file.readlines()\n",
    "\n",
    "    info = {}\n",
    "    spl = filepath.as_posix().split(\"/\")\n",
    "    info['category'] = spl[3]\n",
    "    info['gallery_name'] = spl[4]\n",
    "    info['filenames'] = filenames\n",
    "    for line in content:\n",
    "        if line.startswith(\"Channel\"):\n",
    "            info['channel'] = line.removeprefix(\"Channel: : \").removesuffix(\"\\n\")\n",
    "        elif line.startswith(\"Models\"):\n",
    "            models = process_line(line.removeprefix(\"Models:: \").removesuffix(\" + Suggest\\n\"))\n",
    "            if \"Suggest\" in models:\n",
    "                models.remove(\"Suggest\")\n",
    "            info['models'] = models\n",
    "        elif line.startswith(\"Categories\"):\n",
    "            info['categories'] = process_line(line.removeprefix(\"Categories:: \").removesuffix(\" + Suggest\\n\"))\n",
    "        elif line.startswith(\"Tags List\"):\n",
    "            info['tags_list'] = split_and_unify_tags(process_line(line.removeprefix(\"Tags List:: \").removesuffix(\"\\n\")))\n",
    "        elif line.startswith(\"Stats\"):\n",
    "            splitted = line.removeprefix(\"Stats:: \").removesuffix(\"\\n\").split(\"; \")\n",
    "\n",
    "            try:\n",
    "                info['rating'] = splitted[0].removeprefix(\"Rating: \")\n",
    "            except:\n",
    "                info['rating'] = None\n",
    "\n",
    "            try:\n",
    "                info['views'] = splitted[1].removeprefix(\"Views: \")\n",
    "            except:\n",
    "                info['views'] = None\n",
    "\n",
    "    return info"
   ],
   "id": "f9bd581a52cba412",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_gallery(category_name: str, gallery: str):\n",
    "    gallery_info_path = SRC_DIR / category_name / gallery / 'gallery_info.txt'\n",
    "    if gallery_info_path.exists():\n",
    "        gallery_info = parse_gallery_info(gallery_info_path)\n",
    "        return gallery_info"
   ],
   "id": "f44491fada2060bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_category(category_name: str):\n",
    "    category_path = SRC_DIR / category_name\n",
    "    category_galleries = [\n",
    "        gallery\n",
    "        for gallery in os.listdir(category_path)\n",
    "        if (category_path / gallery).is_dir()\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "        future_to_gallery = [\n",
    "            executor.submit(process_gallery, category_name, gallery)\n",
    "            for gallery in category_galleries\n",
    "        ]\n",
    "\n",
    "        for future in tqdm(\n",
    "                concurrent.futures.as_completed(future_to_gallery),\n",
    "                total=len(future_to_gallery),\n",
    "                desc=f\"Processing {category_name}\",\n",
    "                unit=\"gallery\"\n",
    "        ):\n",
    "            gallery_info = future.result()\n",
    "            if gallery_info:\n",
    "                results.append(gallery_info)\n",
    "\n",
    "    return results"
   ],
   "id": "f2414508c8b9e7da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def crawl_images_folder():\n",
    "    categories = [\n",
    "        category for category in os.listdir(SRC_DIR)\n",
    "        if (SRC_DIR / category).is_dir() and not category.startswith(\".\")\n",
    "    ]\n",
    "\n",
    "    all_galleries_info = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_category = [\n",
    "            executor.submit(process_category, category)\n",
    "            for category in categories\n",
    "        ]\n",
    "        for future in tqdm(\n",
    "                concurrent.futures.as_completed(future_to_category),\n",
    "                total=len(future_to_category),\n",
    "                desc=\"Processing categories\", unit=\"category\"\n",
    "        ):\n",
    "            category_galleries_info = future.result()\n",
    "            all_galleries_info.extend(category_galleries_info)\n",
    "\n",
    "    return all_galleries_info"
   ],
   "id": "76e69a8a11f4a80f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_galleries_info = crawl_images_folder()\n",
    "df = pd.DataFrame(all_galleries_info)"
   ],
   "id": "eb4e3a71e20d3cee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "daf6ddd3d45f1fd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ENHANCED DATAFRAME",
   "id": "7a94c44e4bb8d627"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def process_filenames_to_mini_df(row):\n",
    "    category = row['category']\n",
    "    gallery_name = row['gallery_name']\n",
    "    gallery_dicts = []\n",
    "\n",
    "    def _process_image(category: str, gallery_name: str, filename: str) -> None:\n",
    "        file_path = os.path.join(SRC_DIR, category, gallery_name, filename)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                height, width = img.size\n",
    "                new_row = row.to_dict()\n",
    "                new_row['filename'] = filename\n",
    "                new_row['width'] = width\n",
    "                new_row['height'] = height\n",
    "                gallery_dicts.append(new_row)\n",
    "        except Exception:\n",
    "            print(f\"Error processing {file_path}\")\n",
    "            os.remove(file_path)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [\n",
    "            executor.submit(_process_image, category, gallery_name, filename)\n",
    "            for filename in row['filenames']\n",
    "        ]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            future.result()\n",
    "\n",
    "    return pd.DataFrame(gallery_dicts)"
   ],
   "id": "bf7a4b75bf7f7745",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "futures = []\n",
    "\n",
    "mini_dfs = []\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    mini_dfs.append(process_filenames_to_mini_df(row))"
   ],
   "id": "efd401bb89ca5a74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "enhanced_df = pd.concat(mini_dfs)",
   "id": "f311b71060a11d3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "enhanced_df.shape",
   "id": "38c6dcece80a5567",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "enhanced_df.to_csv('filenames_dataset.csv', index=False)",
   "id": "44fa07adb1715d6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_tags = [sublist for sublist in df['tags_list'].values if sublist != [] and not isinstance(sublist, float)]\n",
    "merged_list = sorted([item for sublist in all_tags for item in sublist])"
   ],
   "id": "601c80ba076350cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset inspection",
   "id": "4349e926d3771dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:05:30.071281Z",
     "start_time": "2024-06-02T09:05:30.069221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def strip_channel_name(channel_name: str):\n",
    "    if isinstance(channel_name, str):\n",
    "        return channel_name.split(\"Pics\")[0].strip()\n",
    "    return channel_name"
   ],
   "id": "4c946da63ac9fd5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:05:36.097450Z",
     "start_time": "2024-06-02T09:05:30.344001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enhanced_df = pd.read_csv('filenames_dataset.csv', index_col=0)\n",
    "enhanced_df.drop(['filenames'], axis=1, inplace=True)\n",
    "enhanced_df['channel'] = enhanced_df.channel.apply(strip_channel_name)"
   ],
   "id": "f45368377f2124d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:05:36.105090Z",
     "start_time": "2024-06-02T09:05:36.098472Z"
    }
   },
   "cell_type": "code",
   "source": "enhanced_df.head()",
   "id": "b2c385f1597d9e14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               gallery_name           channel  \\\n",
       "category                                                                        \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "\n",
       "                  models                                         categories  \\\n",
       "category                                                                      \n",
       "thong     ['Mary Queen']  ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Mary Queen']  ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Mary Queen']  ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Mary Queen']  ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Mary Queen']  ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "\n",
       "                                                  tags_list rating  views  \\\n",
       "category                                                                    \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%  9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%  9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%  9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%  9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%  9,792   \n",
       "\n",
       "                       filename  width  height  \n",
       "category                                        \n",
       "thong     94680408_002_9900.jpg   1280     853  \n",
       "thong     94680408_008_cd7f.jpg   1280     853  \n",
       "thong     94680408_009_1f22.jpg   1280     853  \n",
       "thong     94680408_011_5291.jpg   1280     853  \n",
       "thong     94680408_006_6674.jpg   1280     853  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gallery_name</th>\n",
       "      <th>channel</th>\n",
       "      <th>models</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags_list</th>\n",
       "      <th>rating</th>\n",
       "      <th>views</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_002_9900.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_008_cd7f.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_009_1f22.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_011_5291.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_006_6674.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T09:05:36.215891Z",
     "start_time": "2024-06-02T09:05:36.105851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter out rows where width and height are less than 768\n",
    "enhanced_df = enhanced_df[(enhanced_df['width'] >= 768) & (enhanced_df['height'] >= 768)]\n",
    "enhanced_df"
   ],
   "id": "123e76496214afa7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               gallery_name           channel  \\\n",
       "category                                                                        \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "thong     slutty-blonde-poses-in-sheer-lingerie-with-her...  Strictly Glamour   \n",
       "...                                                     ...               ...   \n",
       "cougar    busty-milf-alura-jenson-enjoying-a-hard-dickin...  Brazzers Network   \n",
       "cougar    busty-milf-alura-jenson-enjoying-a-hard-dickin...  Brazzers Network   \n",
       "cougar    busty-milf-alura-jenson-enjoying-a-hard-dickin...  Brazzers Network   \n",
       "cougar    busty-milf-alura-jenson-enjoying-a-hard-dickin...  Brazzers Network   \n",
       "cougar    busty-milf-alura-jenson-enjoying-a-hard-dickin...  Brazzers Network   \n",
       "\n",
       "                                  models  \\\n",
       "category                                   \n",
       "thong                     ['Mary Queen']   \n",
       "thong                     ['Mary Queen']   \n",
       "thong                     ['Mary Queen']   \n",
       "thong                     ['Mary Queen']   \n",
       "thong                     ['Mary Queen']   \n",
       "...                                  ...   \n",
       "cougar    ['Alura Jenson', 'Robby Echo']   \n",
       "cougar    ['Alura Jenson', 'Robby Echo']   \n",
       "cougar    ['Alura Jenson', 'Robby Echo']   \n",
       "cougar    ['Alura Jenson', 'Robby Echo']   \n",
       "cougar    ['Alura Jenson', 'Robby Echo']   \n",
       "\n",
       "                                                 categories  \\\n",
       "category                                                      \n",
       "thong     ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "thong     ['Stockings', 'Lingerie', 'Babe', 'High Heels'...   \n",
       "...                                                     ...   \n",
       "cougar    ['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...   \n",
       "cougar    ['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...   \n",
       "cougar    ['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...   \n",
       "cougar    ['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...   \n",
       "cougar    ['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...   \n",
       "\n",
       "                                                  tags_list rating    views  \\\n",
       "category                                                                      \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%    9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%    9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%    9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%    9,792   \n",
       "thong     ['Big Tits Babe', 'Blonde Stockings', 'Perfect...    94%    9,792   \n",
       "...                                                     ...    ...      ...   \n",
       "cougar    ['Cougar Seduction', 'Mega Boobs', 'Big Tits F...    94%  257,802   \n",
       "cougar    ['Cougar Seduction', 'Mega Boobs', 'Big Tits F...    94%  257,802   \n",
       "cougar    ['Cougar Seduction', 'Mega Boobs', 'Big Tits F...    94%  257,802   \n",
       "cougar    ['Cougar Seduction', 'Mega Boobs', 'Big Tits F...    94%  257,802   \n",
       "cougar    ['Cougar Seduction', 'Mega Boobs', 'Big Tits F...    94%  257,802   \n",
       "\n",
       "                       filename  width  height  \n",
       "category                                        \n",
       "thong     94680408_002_9900.jpg   1280     853  \n",
       "thong     94680408_008_cd7f.jpg   1280     853  \n",
       "thong     94680408_009_1f22.jpg   1280     853  \n",
       "thong     94680408_011_5291.jpg   1280     853  \n",
       "thong     94680408_006_6674.jpg   1280     853  \n",
       "...                         ...    ...     ...  \n",
       "cougar    13945022_101_24fa.jpg    853    1280  \n",
       "cougar    13945022_067_b810.jpg   1280     853  \n",
       "cougar    13945022_243_f12d.jpg   1280     853  \n",
       "cougar    13945022_324_65b2.jpg    853    1280  \n",
       "cougar    13945022_359_f499.jpg    853    1280  \n",
       "\n",
       "[1266303 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gallery_name</th>\n",
       "      <th>channel</th>\n",
       "      <th>models</th>\n",
       "      <th>categories</th>\n",
       "      <th>tags_list</th>\n",
       "      <th>rating</th>\n",
       "      <th>views</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_002_9900.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_008_cd7f.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_009_1f22.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_011_5291.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thong</th>\n",
       "      <td>slutty-blonde-poses-in-sheer-lingerie-with-her...</td>\n",
       "      <td>Strictly Glamour</td>\n",
       "      <td>['Mary Queen']</td>\n",
       "      <td>['Stockings', 'Lingerie', 'Babe', 'High Heels'...</td>\n",
       "      <td>['Big Tits Babe', 'Blonde Stockings', 'Perfect...</td>\n",
       "      <td>94%</td>\n",
       "      <td>9,792</td>\n",
       "      <td>94680408_006_6674.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cougar</th>\n",
       "      <td>busty-milf-alura-jenson-enjoying-a-hard-dickin...</td>\n",
       "      <td>Brazzers Network</td>\n",
       "      <td>['Alura Jenson', 'Robby Echo']</td>\n",
       "      <td>['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...</td>\n",
       "      <td>['Cougar Seduction', 'Mega Boobs', 'Big Tits F...</td>\n",
       "      <td>94%</td>\n",
       "      <td>257,802</td>\n",
       "      <td>13945022_101_24fa.jpg</td>\n",
       "      <td>853</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cougar</th>\n",
       "      <td>busty-milf-alura-jenson-enjoying-a-hard-dickin...</td>\n",
       "      <td>Brazzers Network</td>\n",
       "      <td>['Alura Jenson', 'Robby Echo']</td>\n",
       "      <td>['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...</td>\n",
       "      <td>['Cougar Seduction', 'Mega Boobs', 'Big Tits F...</td>\n",
       "      <td>94%</td>\n",
       "      <td>257,802</td>\n",
       "      <td>13945022_067_b810.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cougar</th>\n",
       "      <td>busty-milf-alura-jenson-enjoying-a-hard-dickin...</td>\n",
       "      <td>Brazzers Network</td>\n",
       "      <td>['Alura Jenson', 'Robby Echo']</td>\n",
       "      <td>['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...</td>\n",
       "      <td>['Cougar Seduction', 'Mega Boobs', 'Big Tits F...</td>\n",
       "      <td>94%</td>\n",
       "      <td>257,802</td>\n",
       "      <td>13945022_243_f12d.jpg</td>\n",
       "      <td>1280</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cougar</th>\n",
       "      <td>busty-milf-alura-jenson-enjoying-a-hard-dickin...</td>\n",
       "      <td>Brazzers Network</td>\n",
       "      <td>['Alura Jenson', 'Robby Echo']</td>\n",
       "      <td>['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...</td>\n",
       "      <td>['Cougar Seduction', 'Mega Boobs', 'Big Tits F...</td>\n",
       "      <td>94%</td>\n",
       "      <td>257,802</td>\n",
       "      <td>13945022_324_65b2.jpg</td>\n",
       "      <td>853</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cougar</th>\n",
       "      <td>busty-milf-alura-jenson-enjoying-a-hard-dickin...</td>\n",
       "      <td>Brazzers Network</td>\n",
       "      <td>['Alura Jenson', 'Robby Echo']</td>\n",
       "      <td>['Cougar', 'Big Tits', 'BBW', 'MILF', 'Thick',...</td>\n",
       "      <td>['Cougar Seduction', 'Mega Boobs', 'Big Tits F...</td>\n",
       "      <td>94%</td>\n",
       "      <td>257,802</td>\n",
       "      <td>13945022_359_f499.jpg</td>\n",
       "      <td>853</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1266303 rows Ã— 10 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T19:46:57.250818Z",
     "start_time": "2024-06-02T19:46:51.654708Z"
    }
   },
   "cell_type": "code",
   "source": "enhanced_df.to_csv('image_high_res.csv', index=True)",
   "id": "a82b24a55d23f18",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8477259216b143fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
