{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:26:15.286121Z",
     "start_time": "2024-06-09T15:26:15.275478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "11e5c4cb04cffd01",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:26:16.664897Z",
     "start_time": "2024-06-09T15:26:15.565334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from galleries_mapping import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ],
   "id": "15ce2594d9cb1934",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:26:16.677818Z",
     "start_time": "2024-06-09T15:26:16.666651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_tags_count(data: pd.DataFrame | dict):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = Counter([item for sublist in data['labels'] for item in sublist])\n",
    "    sorted_values_cntr = {k: v for k, v in sorted(data.items(), key=lambda item: item[1], reverse=True)}\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pie(\n",
    "        sorted_values_cntr.values(),\n",
    "        labels=sorted_values_cntr.keys(),\n",
    "        autopct='%1.1f%%', startangle=0\n",
    "    )\n",
    "    plt.axis('equal')\n",
    "    plt.title('Label Distribution in Test Set')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_variance_per_key(data: dict):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.bar(data.keys(), data.values())\n",
    "    plt.title('Label Distribution in Test Set')\n",
    "    plt.show()"
   ],
   "id": "30decf585371e094",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:27:10.360117Z",
     "start_time": "2024-06-09T15:26:16.678432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SRC_DIR = Path('/Volumes/external_drive')\n",
    "FILTERED_PORNHUB_CATEGORIES = [\n",
    "    'anal',\n",
    "    'bbw',\n",
    "    'big ass',\n",
    "    'big dick',\n",
    "    'big tits',\n",
    "    'blonde',\n",
    "    'blowjob',\n",
    "    'bondage',\n",
    "    'brunette',\n",
    "    'cosplay',\n",
    "    'creampie',\n",
    "    'cumshot',\n",
    "    'double penetration',\n",
    "    'ebony',\n",
    "    'feet',\n",
    "    'fingering',\n",
    "    'fisting',\n",
    "    'handjob',\n",
    "    'hardcore',\n",
    "    'lesbian',\n",
    "    'massage',\n",
    "    'masturbation',\n",
    "    'milf',\n",
    "    'old/young',\n",
    "    'pissing',\n",
    "    'public',\n",
    "    'pussy licking',\n",
    "    'red head',\n",
    "    'rough sex',\n",
    "    'small tits',\n",
    "    'smoking',\n",
    "    'solo',\n",
    "    'squirt',\n",
    "    'strap on',\n",
    "    'striptease',\n",
    "    'tattooed women',\n",
    "    'teen',\n",
    "    'threesome',\n",
    "    'toys',\n",
    "    'transgender'\n",
    "]\n",
    "\n",
    "try:\n",
    "    _df = pd.read_csv('datasets/images_high_res_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    _df = pd.read_csv(SRC_DIR / 'images_high_res_dataset.csv')\n",
    "\n",
    "print(\"Dataset loaded.\")\n",
    "_df.drop(['models'], axis=1, inplace=True)\n",
    "_df['categories'] = _df['categories'].apply(ast.literal_eval)\n",
    "_df['categories_suggestions'] = _df['categories_suggestions'].apply(ast.literal_eval)\n",
    "print(\"Parsed list columns categories\")"
   ],
   "id": "15b18486f048e9b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "Parsed list columns categories\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T15:27:10.626326Z",
     "start_time": "2024-06-09T15:27:10.361339Z"
    }
   },
   "source": [
    "df = _df.copy(True)\n",
    "df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345430, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge suggestions and categories",
   "id": "9d71a0bef332167b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:28:38.000332Z",
     "start_time": "2024-06-09T15:28:16.678122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_categories(row):\n",
    "    categories = set(row['categories'])\n",
    "    categories_suggestions = set(row['categories_suggestions'])\n",
    "    categories_superset = {category.strip().lower() for category in categories.union(categories_suggestions)}\n",
    "    return list(categories_superset)\n",
    "\n",
    "\n",
    "df['labels'] = df['categories'].apply(lambda x: [category.strip().lower() for category in x])\n",
    "df['labels'] = df.apply(merge_categories, axis=1)\n",
    "df.drop(['categories_suggestions', 'categories'], axis=1, inplace=True)\n",
    "df.shape"
   ],
   "id": "b966e6edb3fbb00f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345430, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Purge nationalities from tags",
   "id": "ce451a7c7dad68d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:28:43.399025Z",
     "start_time": "2024-06-09T15:28:38.002282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nationality_tags_to_purge = {\n",
    "    'african',\n",
    "    'american',\n",
    "    'arab',\n",
    "    'argentina',\n",
    "    'australian',\n",
    "    'brazilian',\n",
    "    'british',\n",
    "    'canadian',\n",
    "    'chinese',\n",
    "    'colombian',\n",
    "    'cuban',\n",
    "    'czech',\n",
    "    'dutch',\n",
    "    'european',\n",
    "    'filipina',\n",
    "    'french',\n",
    "    'german',\n",
    "    'hungarian',\n",
    "    'indian',\n",
    "    'italian',\n",
    "    'japanese',\n",
    "    'korean',\n",
    "    'mexican',\n",
    "    'pinay',\n",
    "    'polish',\n",
    "    'russian',\n",
    "    'spanish',\n",
    "    'thai',\n",
    "    'ukrainian',\n",
    "    'venezuela',\n",
    "    'white'\n",
    "}\n",
    "nationality_tags_to_purge = {n.lower() for n in nationality_tags_to_purge}\n",
    "df['labels'] = df.labels.apply(lambda x: list(set(x) - nationality_tags_to_purge))\n",
    "df.shape"
   ],
   "id": "8b389e8c51247db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345430, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply gallery mapping",
   "id": "11b02068325bb595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:28:52.277438Z",
     "start_time": "2024-06-09T15:28:43.399847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gallery_mapping(row):\n",
    "    labels = row.labels\n",
    "\n",
    "    out = []\n",
    "    for L in labels:\n",
    "        _fetched = GALLERIES_MAP.get(L, None)\n",
    "        if _fetched is remove_tag:\n",
    "            continue\n",
    "        elif _fetched is remove_gallery:\n",
    "            return None\n",
    "        elif isinstance(_fetched, list):\n",
    "            out.extend(_fetched)\n",
    "        elif _fetched is keep_tag:\n",
    "            out.append(L.lower())\n",
    "\n",
    "    return list(set(out))\n",
    "\n",
    "\n",
    "df['labels'] = df.apply(gallery_mapping, axis=1)\n",
    "df = df[df['labels'].notnull()]\n",
    "df.shape"
   ],
   "id": "cb3d10abc08de8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114113, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataframe clean up",
   "id": "ca90d0758c17d418"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:29:00.998463Z",
     "start_time": "2024-06-09T15:29:00.525112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['file_path'] = df['gallery_category'] + '/' + df['gallery_name'] + '/' + df['filename']\n",
    "df = df.drop(\n",
    "    ['gallery_category', 'gallery_name', 'filename'], axis=1\n",
    ")\n",
    "df.reset_index(inplace=True, drop=True)"
   ],
   "id": "d8efbbb40b2d5354",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:29:03.235414Z",
     "start_time": "2024-06-09T15:29:03.115955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop(\n",
    "    ['height', 'width'], axis=1, inplace=True\n",
    ")"
   ],
   "id": "c36021bb7a92e2a8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:29:03.615244Z",
     "start_time": "2024-06-09T15:29:03.604245Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "9711b161b73c9bd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114113, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:29:26.595736Z",
     "start_time": "2024-06-09T15:29:21.944493Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv('datasets/all_file_paths.csv')",
   "id": "21614e1341460ad",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Balancing the dataset",
   "id": "ec520848e852cd79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:31:03.953962Z",
     "start_time": "2024-06-09T15:31:02.435174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_counts = Counter(item for sublist in df['labels'] for item in sublist)\n",
    "ascending_labels = [\n",
    "    k for k, v in sorted(label_counts.items(), key=lambda item: item[1])\n",
    "]\n",
    "label_proportions = {\n",
    "    k: v / len(df) for k, v in sorted(label_counts.items(), key=lambda item: item[1])\n",
    "}"
   ],
   "id": "62f4b7d80adc8120",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:35:09.564068Z",
     "start_time": "2024-06-09T15:35:09.547147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_balanced_df(og_df, max_samples=1000):\n",
    "    def get_rows_with_label(dataframe, label):\n",
    "        return dataframe[dataframe['labels'].apply(lambda x: label in x)]\n",
    "\n",
    "    balanced_dfs = {label: pd.DataFrame() for label in label_counts.keys()}\n",
    "\n",
    "    for label in tqdm(ascending_labels, total=len(ascending_labels), desc='Balancing dataset'):\n",
    "        label_df = get_rows_with_label(og_df, label)\n",
    "\n",
    "        label_df = resample(\n",
    "            label_df,\n",
    "            n_samples=max_samples,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        balanced_dfs[label] = label_df\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs).drop_duplicates(subset='file_path').reset_index(drop=True)\n",
    "\n",
    "    return balanced_df"
   ],
   "id": "b10818658a6b926f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:36:13.371025Z",
     "start_time": "2024-06-09T15:35:10.887449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_balanced_df = get_balanced_df(df, max_samples=1000)\n",
    "medium_balanced_df = get_balanced_df(df, max_samples=3000)\n",
    "final_balanced_df = df.copy()"
   ],
   "id": "f588be2b183f02cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing dataset: 100%|██████████| 113/113 [00:31<00:00,  3.55it/s]\n",
      "Balancing dataset: 100%|██████████| 113/113 [00:30<00:00,  3.72it/s]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:36:20.278689Z",
     "start_time": "2024-06-09T15:36:13.372572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_balanced_df.to_csv('datasets/small_file_paths.csv')\n",
    "medium_balanced_df.to_csv('datasets/medium_file_paths.csv')\n",
    "final_balanced_df.to_csv('datasets/all_file_paths.csv')"
   ],
   "id": "b333515d7d6b9f61",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# One hot encoding",
   "id": "987dbcf9cbcb084f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:36:20.314266Z",
     "start_time": "2024-06-09T15:36:20.282252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataframe_one_hot_encoding(dataframe: pd.DataFrame):\n",
    "    all_labels = set(label for labels in dataframe['labels'] for label in labels)\n",
    "    one_hot_encoded = pd.DataFrame()\n",
    "\n",
    "    for label in tqdm(all_labels, total=len(all_labels), desc='One hot encoding'):\n",
    "        one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
    "\n",
    "    final_df = pd.concat([dataframe, one_hot_encoded], axis=1)\n",
    "    final_df = final_df.drop(columns=['labels', ], axis=1)\n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cols_sorted = sorted(list(final_df.columns))\n",
    "    cols_sorted.remove(\"file_path\")\n",
    "\n",
    "    final_df = final_df[[\"file_path\", *cols_sorted]]\n",
    "\n",
    "    return final_df"
   ],
   "id": "abf9265e0e1bd634",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:37:41.287221Z",
     "start_time": "2024-06-09T15:36:27.725715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_final_df = dataframe_one_hot_encoding(small_balanced_df)\n",
    "medium_final_df = dataframe_one_hot_encoding(medium_balanced_df)\n",
    "final_df = dataframe_one_hot_encoding(df)"
   ],
   "id": "6a6ab137d48e228c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One hot encoding:  88%|████████▊ | 100/113 [00:06<00:00, 13.99it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  90%|█████████ | 102/113 [00:07<00:00, 14.28it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  92%|█████████▏| 104/113 [00:07<00:00, 14.31it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  94%|█████████▍| 106/113 [00:07<00:00, 14.15it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▌| 108/113 [00:07<00:00, 14.10it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  97%|█████████▋| 110/113 [00:07<00:00, 14.06it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  99%|█████████▉| 112/113 [00:07<00:00, 14.13it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 113/113 [00:07<00:00, 14.36it/s]\n",
      "One hot encoding:  88%|████████▊ | 100/113 [00:17<00:02,  5.62it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  89%|████████▉ | 101/113 [00:18<00:02,  5.60it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  90%|█████████ | 102/113 [00:18<00:01,  5.62it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  91%|█████████ | 103/113 [00:18<00:01,  5.51it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  92%|█████████▏| 104/113 [00:18<00:01,  5.53it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  93%|█████████▎| 105/113 [00:18<00:01,  5.57it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  94%|█████████▍| 106/113 [00:18<00:01,  5.58it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▍| 107/113 [00:19<00:01,  5.56it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▌| 108/113 [00:19<00:00,  5.60it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▋| 109/113 [00:19<00:00,  5.59it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  97%|█████████▋| 110/113 [00:19<00:00,  5.66it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  98%|█████████▊| 111/113 [00:19<00:00,  5.66it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  99%|█████████▉| 112/113 [00:19<00:00,  5.54it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 113/113 [00:20<00:00,  5.60it/s]\n",
      "One hot encoding:  88%|████████▊ | 100/113 [00:35<00:04,  2.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  89%|████████▉ | 101/113 [00:36<00:04,  2.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  90%|█████████ | 102/113 [00:36<00:03,  2.89it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  91%|█████████ | 103/113 [00:36<00:03,  2.86it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  92%|█████████▏| 104/113 [00:37<00:03,  2.86it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  93%|█████████▎| 105/113 [00:37<00:02,  2.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  94%|█████████▍| 106/113 [00:37<00:02,  2.80it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▍| 107/113 [00:38<00:02,  2.80it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▌| 108/113 [00:38<00:01,  2.80it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▋| 109/113 [00:39<00:01,  2.79it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  97%|█████████▋| 110/113 [00:39<00:01,  2.78it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  98%|█████████▊| 111/113 [00:39<00:00,  2.78it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  99%|█████████▉| 112/113 [00:40<00:00,  2.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_46410/3430957949.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 113/113 [00:40<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:37:57.397847Z",
     "start_time": "2024-06-09T15:37:41.289109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_final_df.to_csv(\"datasets/small_one_hot.csv\")\n",
    "medium_final_df.to_csv(\"datasets/medium_one_hot.csv\")\n",
    "final_df.to_csv(\"datasets/full_one_hot.csv\")"
   ],
   "id": "98837d5e88bc407c",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AI GEN",
   "id": "ee32b06064f70ad6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:14.518998Z",
     "start_time": "2024-06-09T15:38:14.506771Z"
    }
   },
   "cell_type": "code",
   "source": "df.shape",
   "id": "7f9fa32592398808",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114113, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:17.055873Z",
     "start_time": "2024-06-09T15:38:17.039980Z"
    }
   },
   "cell_type": "code",
   "source": "from galleries_mapping import *",
   "id": "245d5295e00ee279",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:18.235542Z",
     "start_time": "2024-06-09T15:38:18.216820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_mandatory_columns = [\n",
    "    'age',\n",
    "]\n",
    "mandatory_columns = list(\n",
    "    x.strip() for x in AI_GEN_TAGS[_mandatory_columns].values.flatten() if isinstance(x, str)\n",
    ")\n",
    "_negative_columns = [\n",
    "    'negative', 'more_people'\n",
    "]\n",
    "negative_columns = list(\n",
    "    x.strip() for x in AI_GEN_TAGS[_negative_columns].values.flatten() if isinstance(x, str)\n",
    ")\n",
    "tags_to_drop = {\n",
    "    'blowjob', 'reality', 'hardcore', 'cumshot', 'cowgirl', 'ass fucking', 'doggy style', 'teen', 'lesbian', 'model',\n",
    "    'big cock', 'anal', 'bdsm', 'bondage', 'fetish', 'face', 'kissing', 'handjob', 'facial', 'fingering', 'groupsex',\n",
    "    'cum in mouth', 'old young', 'titjob', 'interracial', 'pussy licking', 'threesome', 'pov', 'femdom', 'christmas',\n",
    "    'girlfriend', 'cosplay', 'facesitting', 'massage', 'deepthroat', 'strapon', 'cheating', 'humping', 'cum in pussy',\n",
    "    'ass licking', 'creampie', 'ball licking', 'spanking', 'orgasm', 'double penetration', 'couple', 'family',\n",
    "    'anal gape', 'bbc', 'party', 'schoolgirl', 'fisting', 'missionary', 'squirting', 'pissing', 'gangbang', 'old man',\n",
    "    'ffm', 'cuckold', 'seduction', 'tribbing', 'orgy', 'flexible', 'cfnm', 'footjob', 'blowbang', 'pegging', 'pregnant',\n",
    "    'swingers', 'gloryhole', 'caught', 'college', 'yoga', 'casting', 'stripper', 'step sister', 'voyeur', 'mmf',\n",
    "    'bukkake', 'gyno', 'small cock', 'babysitter', 'cheerleader', 'cum swapping', 'bisexual', 'goth', 'braces', 'pawg',\n",
    "    'pretty', 'pigtails', 'emo', 'latex', 'babe', 'step brother', 'twink', 'shemale', 'ballerina', 'twins', 'pornstar',\n",
    "    'model', 'latex', 'emo', 'latex', 'babe', 'leather', 'pigtails', 'halloween', 'wedding',\n",
    "    'tall', 'doctor', 'vintage'\n",
    "}"
   ],
   "id": "6e7ad93db80bdceb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:37.989713Z",
     "start_time": "2024-06-09T15:38:30.597544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_positives(row):\n",
    "    labels = row.labels\n",
    "\n",
    "    for L in labels:\n",
    "        if L in mandatory_columns:\n",
    "            return labels\n",
    "\n",
    "\n",
    "def filter_negatives(row):\n",
    "    labels = row.labels\n",
    "    for L in labels:\n",
    "        if L in negative_columns:\n",
    "            # print(f\"Label {L} in negative_columns.\")\n",
    "            return None\n",
    "        if L in tags_to_drop:\n",
    "            # print(f\"Label {L} in tags_to_drop.\")\n",
    "            return None\n",
    "        # print(f\"Label {L} is allowed.\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "ai_df = df.copy()\n",
    "ai_df['labels'] = ai_df.apply(filter_positives, axis=1)\n",
    "ai_df = ai_df[ai_df['labels'].notnull()]\n",
    "print(ai_df.shape)\n",
    "\n",
    "ai_df['labels'] = ai_df.apply(filter_negatives, axis=1)\n",
    "ai_df = ai_df[ai_df['labels'].notnull()]\n",
    "print(ai_df.shape)"
   ],
   "id": "204714d7afc63961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332966, 2)\n",
      "(80250, 2)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:38.008453Z",
     "start_time": "2024-06-09T15:38:37.991919Z"
    }
   },
   "cell_type": "code",
   "source": "ai_df.reset_index(inplace=True, drop=True)",
   "id": "d2d1d839fa6a8277",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:38.188850Z",
     "start_time": "2024-06-09T15:38:38.009283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_df['labels_length'] = ai_df['labels'].apply(len)\n",
    "ai_df = ai_df[ai_df['labels_length'] > 5]\n",
    "ai_df.drop(['labels_length'], axis=1, inplace=True)\n",
    "ai_df.reset_index(drop=True, inplace=True)\n",
    "ai_df.to_csv('datasets/ai_gen_dataset_5_cats.csv')\n",
    "print(\"5 cats df shape:\", ai_df.shape)\n",
    "\n",
    "ai_df['labels_length'] = ai_df['labels'].apply(len)\n",
    "ai_df = ai_df[ai_df['labels_length'] > 10]\n",
    "ai_df.drop(['labels_length'], axis=1, inplace=True)\n",
    "ai_df.reset_index(drop=True, inplace=True)\n",
    "ai_df.to_csv('datasets/ai_gen_dataset_10_cats.csv')\n",
    "print(\"10 cats df shape:\", ai_df.shape)"
   ],
   "id": "81ed07c39db2ce96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 cats df shape: (27112, 2)\n",
      "10 cats df shape: (10524, 2)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:38.211688Z",
     "start_time": "2024-06-09T15:38:38.190034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_labels = [label for labels in ai_df['labels'] for label in labels]\n",
    "cntr = Counter(all_labels)\n",
    "cntr"
   ],
   "id": "72a8ce7e76788872",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'milf': 8179,\n",
       "         'big tits': 7803,\n",
       "         'spreading': 7304,\n",
       "         'pussy': 6994,\n",
       "         'legs': 5795,\n",
       "         'clothed': 5713,\n",
       "         'panties': 5618,\n",
       "         'heels': 5146,\n",
       "         'nipples': 4944,\n",
       "         'mature': 4704,\n",
       "         'close up': 4468,\n",
       "         'solo': 4224,\n",
       "         'brunette': 4184,\n",
       "         'thick': 4079,\n",
       "         'curvy': 4079,\n",
       "         'chubby': 4079,\n",
       "         'bbw': 4079,\n",
       "         'masturbation': 4031,\n",
       "         'skirt': 3964,\n",
       "         'blonde': 3659,\n",
       "         'lingerie': 3588,\n",
       "         'dildo': 3313,\n",
       "         'sex toys': 3313,\n",
       "         'undressing': 3193,\n",
       "         'stockings': 3077,\n",
       "         'shaved': 2831,\n",
       "         'hairy': 2258,\n",
       "         'upskirt': 2201,\n",
       "         'feet': 1472,\n",
       "         'outdoor': 1347,\n",
       "         'tattoo': 1288,\n",
       "         'redhead': 1276,\n",
       "         'tiny tits': 1238,\n",
       "         'armpit': 1237,\n",
       "         'glasses': 1196,\n",
       "         'uniform': 820,\n",
       "         'pantyhose': 792,\n",
       "         'smoking': 734,\n",
       "         'dress': 697,\n",
       "         'skinny': 676,\n",
       "         'latina': 670,\n",
       "         'granny': 614,\n",
       "         'office': 584,\n",
       "         'bath': 532,\n",
       "         'bikini': 509,\n",
       "         'asian': 501,\n",
       "         'oiled': 439,\n",
       "         'shorts': 427,\n",
       "         'petite': 399,\n",
       "         'jeans': 395,\n",
       "         'pool': 367,\n",
       "         'curly': 341,\n",
       "         'shower': 303,\n",
       "         'public': 293,\n",
       "         'boots': 266,\n",
       "         'socks': 262,\n",
       "         'ebony': 246,\n",
       "         'nurse': 246,\n",
       "         'sports': 198,\n",
       "         'selfie': 157,\n",
       "         'maid': 125,\n",
       "         'beach': 118,\n",
       "         'teacher': 104,\n",
       "         'yoga pants': 99,\n",
       "         'pants': 90,\n",
       "         'cameltoe': 90,\n",
       "         'sandals': 83,\n",
       "         'rough sex': 73,\n",
       "         'thong': 71,\n",
       "         'ssbbw': 52,\n",
       "         'gym': 20})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:38:42.684499Z",
     "start_time": "2024-06-09T15:38:42.666759Z"
    }
   },
   "cell_type": "code",
   "source": "ai_df.head()",
   "id": "ca9941eed9deb78d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              labels  \\\n",
       "0  [heels, legs, nipples, clothed, shaved, close ...   \n",
       "1  [heels, legs, nipples, clothed, shaved, close ...   \n",
       "2  [heels, legs, nipples, clothed, shaved, close ...   \n",
       "3  [heels, legs, nipples, clothed, shaved, close ...   \n",
       "4  [heels, legs, nipples, clothed, shaved, close ...   \n",
       "\n",
       "                                           file_path  \n",
       "0  big-tits/super-busty-blonde-mary-carey-lets-he...  \n",
       "1  big-tits/super-busty-blonde-mary-carey-lets-he...  \n",
       "2  big-tits/super-busty-blonde-mary-carey-lets-he...  \n",
       "3  big-tits/super-busty-blonde-mary-carey-lets-he...  \n",
       "4  big-tits/super-busty-blonde-mary-carey-lets-he...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[heels, legs, nipples, clothed, shaved, close ...</td>\n",
       "      <td>big-tits/super-busty-blonde-mary-carey-lets-he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heels, legs, nipples, clothed, shaved, close ...</td>\n",
       "      <td>big-tits/super-busty-blonde-mary-carey-lets-he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[heels, legs, nipples, clothed, shaved, close ...</td>\n",
       "      <td>big-tits/super-busty-blonde-mary-carey-lets-he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[heels, legs, nipples, clothed, shaved, close ...</td>\n",
       "      <td>big-tits/super-busty-blonde-mary-carey-lets-he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[heels, legs, nipples, clothed, shaved, close ...</td>\n",
       "      <td>big-tits/super-busty-blonde-mary-carey-lets-he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6a889452ea3eb7d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
