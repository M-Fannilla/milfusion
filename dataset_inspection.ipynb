{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:19:31.992986Z",
     "start_time": "2024-06-12T11:19:31.977572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "11e5c4cb04cffd01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:19:32.109538Z",
     "start_time": "2024-06-12T11:19:32.099070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample"
   ],
   "id": "15ce2594d9cb1934",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:19:32.482304Z",
     "start_time": "2024-06-12T11:19:32.471041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_tags_count(data: pd.DataFrame | dict, zoom_max=10000):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = Counter([item for sublist in data['labels'] for item in sublist])\n",
    "    sorted_values_cntr = {k: v for k, v in sorted(data.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    if zoom_max:\n",
    "        sorted_values_cntr = {k: v for k, v in sorted_values_cntr.items() if v < zoom_max}\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pie(\n",
    "        sorted_values_cntr.values(),\n",
    "        labels=sorted_values_cntr.keys(),\n",
    "        autopct='%1.1f%%', startangle=0\n",
    "    )\n",
    "    plt.axis('equal')\n",
    "    plt.title('Label Distribution in Test Set')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_variance_per_key(data: dict):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.bar(data.keys(), data.values())\n",
    "    plt.title('Label Distribution in Test Set')\n",
    "    plt.show()"
   ],
   "id": "30decf585371e094",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:23:25.312655Z",
     "start_time": "2024-06-12T11:22:14.833792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SRC_DIR = Path('/Volumes/external_drive')\n",
    "\n",
    "try:\n",
    "    _df = pd.read_csv('datasets/images_high_res_dataset.csv')\n",
    "except FileNotFoundError:\n",
    "    _df = pd.read_csv(SRC_DIR / 'images_high_res_dataset.csv')\n",
    "\n",
    "print(\"Dataset loaded.\")\n",
    "_df['categories'] = _df['categories'].apply(ast.literal_eval)\n",
    "_df['categories_suggestions'] = _df['categories_suggestions'].apply(ast.literal_eval)\n",
    "print(\"Parsed list columns categories\")"
   ],
   "id": "15b18486f048e9b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "Parsed list columns categories\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T11:23:26.751726Z",
     "start_time": "2024-06-12T11:23:25.315183Z"
    }
   },
   "source": [
    "df = _df.copy(True)\n",
    "df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344601, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge suggestions and categories",
   "id": "9d71a0bef332167b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:23:54.127497Z",
     "start_time": "2024-06-12T11:23:26.752418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_categories(row):\n",
    "    categories = set(row['categories'])\n",
    "    categories_suggestions = set(row['categories_suggestions'])\n",
    "    categories_superset = {category.strip().lower() for category in categories.union(categories_suggestions)}\n",
    "    return list(categories_superset)\n",
    "\n",
    "\n",
    "df['labels'] = df['categories'].apply(lambda x: [category.strip().lower() for category in x])\n",
    "df['labels'] = df.apply(merge_categories, axis=1)\n",
    "df.drop(['categories_suggestions', 'categories'], axis=1, inplace=True)\n",
    "df.shape"
   ],
   "id": "b966e6edb3fbb00f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344601, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Purge nationalities from tags",
   "id": "ce451a7c7dad68d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:23:55.800262Z",
     "start_time": "2024-06-12T11:23:54.130010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nationality_tags_to_purge = {\n",
    "    'african',\n",
    "    'american',\n",
    "    'arab',\n",
    "    'argentina',\n",
    "    'australian',\n",
    "    'brazilian',\n",
    "    'british',\n",
    "    'canadian',\n",
    "    'chinese',\n",
    "    'colombian',\n",
    "    'cuban',\n",
    "    'czech',\n",
    "    'dutch',\n",
    "    'european',\n",
    "    'filipina',\n",
    "    'french',\n",
    "    'german',\n",
    "    'hungarian',\n",
    "    'indian',\n",
    "    'italian',\n",
    "    'japanese',\n",
    "    'korean',\n",
    "    'mexican',\n",
    "    'pinay',\n",
    "    'polish',\n",
    "    'russian',\n",
    "    'spanish',\n",
    "    'thai',\n",
    "    'ukrainian',\n",
    "    'venezuela',\n",
    "    'white'\n",
    "}\n",
    "nationality_tags_to_purge = {n.lower() for n in nationality_tags_to_purge}\n",
    "df['labels'] = df.labels.apply(lambda x: list(set(x) - nationality_tags_to_purge))\n",
    "df.shape"
   ],
   "id": "8b389e8c51247db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344601, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Apply gallery mapping",
   "id": "11b02068325bb595"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:24:12.789956Z",
     "start_time": "2024-06-12T11:23:55.800986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from galleries_mapping import *\n",
    "\n",
    "df_not_mapped = df.copy(True)\n",
    "\n",
    "\n",
    "def gallery_mapping(row):\n",
    "    labels = row.labels\n",
    "\n",
    "    out = []\n",
    "    for L in labels:\n",
    "        _fetched = GALLERIES_MAP.get(L, None)\n",
    "        if _fetched is remove_tag:\n",
    "            continue\n",
    "        elif _fetched is remove_gallery:\n",
    "            return None\n",
    "        elif isinstance(_fetched, list):\n",
    "            out.extend(_fetched)\n",
    "        elif _fetched is keep_tag:\n",
    "            out.append(L.lower())\n",
    "\n",
    "    return list(set(out))\n",
    "\n",
    "\n",
    "df['labels'] = df.apply(gallery_mapping, axis=1)\n",
    "df = df[df['labels'].notnull()]\n",
    "df.shape"
   ],
   "id": "cb3d10abc08de8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1106872, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataframe clean up",
   "id": "ca90d0758c17d418"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:24:13.180282Z",
     "start_time": "2024-06-12T11:24:12.791386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_file_path_column(dataframe: pd.DataFrame):\n",
    "    dataframe['file_path'] = dataframe['gallery_category'] + '/' + dataframe['gallery_name'] + '/' + dataframe[\n",
    "        'filename']\n",
    "    dataframe = dataframe.drop(\n",
    "        ['gallery_category', 'gallery_name', 'filename'], axis=1\n",
    "    )\n",
    "    dataframe.reset_index(inplace=True, drop=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "df.drop(\n",
    "    ['height', 'width'], axis=1, inplace=True\n",
    ")\n",
    "\n",
    "df = add_file_path_column(df)"
   ],
   "id": "d8efbbb40b2d5354",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Balancing the dataset",
   "id": "ec520848e852cd79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:24:14.578106Z",
     "start_time": "2024-06-12T11:24:13.183249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_counts = Counter(item for sublist in df['labels'] for item in sublist)\n",
    "ascending_labels = [\n",
    "    k for k, v in sorted(label_counts.items(), key=lambda item: item[1])\n",
    "]\n",
    "label_proportions = {\n",
    "    k: v / len(df) for k, v in sorted(label_counts.items(), key=lambda item: item[1])\n",
    "}"
   ],
   "id": "62f4b7d80adc8120",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:24:14.590768Z",
     "start_time": "2024-06-12T11:24:14.578979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_balanced_df(og_df, max_samples=1000):\n",
    "    def get_rows_with_label(dataframe, label):\n",
    "        return dataframe[dataframe['labels'].apply(lambda x: label in x)]\n",
    "\n",
    "    balanced_dfs = {label: pd.DataFrame() for label in label_counts.keys()}\n",
    "\n",
    "    for label in tqdm(ascending_labels, total=len(ascending_labels), desc='Balancing dataset'):\n",
    "        label_df = get_rows_with_label(og_df, label)\n",
    "\n",
    "        label_df = resample(\n",
    "            label_df,\n",
    "            n_samples=max_samples,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        balanced_dfs[label] = label_df\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs).drop_duplicates(subset='file_path').reset_index(drop=True)\n",
    "\n",
    "    return balanced_df"
   ],
   "id": "b10818658a6b926f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:25:06.747516Z",
     "start_time": "2024-06-12T11:24:14.591689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_balanced_df = get_balanced_df(df, max_samples=1000)\n",
    "medium_balanced_df = get_balanced_df(df, max_samples=3000)\n",
    "final_balanced_df = df.copy()"
   ],
   "id": "f588be2b183f02cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Balancing dataset: 100%|██████████| 110/110 [00:25<00:00,  4.24it/s]\n",
      "Balancing dataset: 100%|██████████| 110/110 [00:25<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:25:13.347340Z",
     "start_time": "2024-06-12T11:25:06.750603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_balanced_df.to_csv('datasets/small_file_paths.csv')\n",
    "medium_balanced_df.to_csv('datasets/medium_file_paths.csv')\n",
    "final_balanced_df.to_csv('datasets/all_file_paths.csv')"
   ],
   "id": "b333515d7d6b9f61",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# One hot encoding",
   "id": "987dbcf9cbcb084f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:25:13.373981Z",
     "start_time": "2024-06-12T11:25:13.349173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataframe_one_hot_encoding(dataframe: pd.DataFrame):\n",
    "    all_labels = set(label for labels in dataframe['labels'] for label in labels)\n",
    "    one_hot_encoded = pd.DataFrame()\n",
    "\n",
    "    for label in tqdm(all_labels, total=len(all_labels), desc='One hot encoding'):\n",
    "        one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
    "\n",
    "    out_df = pd.concat([dataframe, one_hot_encoded], axis=1)\n",
    "    out_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cols_sorted = sorted(list(out_df.columns))\n",
    "    cols_sorted.remove(\"file_path\")\n",
    "    cols_sorted.remove(\"labels\")\n",
    "\n",
    "    return out_df[[\"file_path\", \"labels\", *cols_sorted]]"
   ],
   "id": "abf9265e0e1bd634",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:19.329013Z",
     "start_time": "2024-06-12T11:25:13.374919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_final_df = dataframe_one_hot_encoding(small_balanced_df)\n",
    "medium_final_df = dataframe_one_hot_encoding(medium_balanced_df)\n",
    "final_df = dataframe_one_hot_encoding(df)"
   ],
   "id": "6a6ab137d48e228c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One hot encoding:  91%|█████████ | 100/110 [00:06<00:00, 14.58it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  93%|█████████▎| 102/110 [00:06<00:00, 14.81it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▍| 104/110 [00:06<00:00, 14.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▋| 106/110 [00:07<00:00, 14.87it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  98%|█████████▊| 108/110 [00:07<00:00, 14.74it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 110/110 [00:07<00:00, 14.85it/s]\n",
      "One hot encoding:  91%|█████████ | 100/110 [00:16<00:01,  5.83it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  92%|█████████▏| 101/110 [00:17<00:01,  5.89it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  93%|█████████▎| 102/110 [00:17<00:01,  5.99it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  94%|█████████▎| 103/110 [00:17<00:01,  6.07it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▍| 104/110 [00:17<00:00,  6.03it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▌| 105/110 [00:17<00:00,  6.11it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▋| 106/110 [00:17<00:00,  6.05it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  97%|█████████▋| 107/110 [00:18<00:00,  5.98it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  98%|█████████▊| 108/110 [00:18<00:00,  5.93it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  99%|█████████▉| 109/110 [00:18<00:00,  5.82it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 110/110 [00:18<00:00,  5.91it/s]\n",
      "One hot encoding:  91%|█████████ | 100/110 [00:33<00:03,  3.03it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  92%|█████████▏| 101/110 [00:33<00:02,  3.03it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  93%|█████████▎| 102/110 [00:33<00:02,  3.10it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  94%|█████████▎| 103/110 [00:34<00:02,  3.11it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▍| 104/110 [00:34<00:01,  3.09it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  95%|█████████▌| 105/110 [00:34<00:01,  3.11it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  96%|█████████▋| 106/110 [00:34<00:01,  3.10it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  97%|█████████▋| 107/110 [00:35<00:00,  3.03it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  98%|█████████▊| 108/110 [00:35<00:00,  3.00it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding:  99%|█████████▉| 109/110 [00:36<00:00,  2.97it/s]/var/folders/cq/qnm4dkj53rq748w0d5l1yz5h0000gn/T/ipykernel_55395/4168988818.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  one_hot_encoded[label] = dataframe['labels'].apply(lambda x: 1 if label in x else 0)\n",
      "One hot encoding: 100%|██████████| 110/110 [00:36<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:39.877829Z",
     "start_time": "2024-06-12T11:26:19.330699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "small_final_df.to_csv(\"datasets/small_one_hot.csv\")\n",
    "medium_final_df.to_csv(\"datasets/medium_one_hot.csv\")\n",
    "final_df.to_csv(\"datasets/all_one_hot.csv\")"
   ],
   "id": "98837d5e88bc407c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AI GEN",
   "id": "ee32b06064f70ad6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:39.907684Z",
     "start_time": "2024-06-12T11:26:39.879404Z"
    }
   },
   "cell_type": "code",
   "source": "from galleries_mapping import *",
   "id": "245d5295e00ee279",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:39.922555Z",
     "start_time": "2024-06-12T11:26:39.908596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_mandatory_columns = [\n",
    "    'age',\n",
    "]\n",
    "mandatory_columns = list(\n",
    "    x.strip() for x in AI_GEN_TAGS[_mandatory_columns].values.flatten() if isinstance(x, str)\n",
    ")\n",
    "_negative_columns = [\n",
    "    'negative', 'more_people'\n",
    "]\n",
    "negative_columns = list(\n",
    "    x.strip() for x in AI_GEN_TAGS[_negative_columns].values.flatten() if isinstance(x, str)\n",
    ")\n",
    "tags_to_drop = {\n",
    "    'blowjob', 'reality', 'hardcore', 'cumshot', 'cowgirl', 'ass fucking', 'doggy style', 'teen', 'lesbian', 'model',\n",
    "    'big cock', 'anal', 'bdsm', 'bondage', 'fetish', 'face', 'kissing', 'handjob', 'facial', 'fingering', 'groupsex',\n",
    "    'cum in mouth', 'old young', 'titjob', 'interracial', 'pussy licking', 'threesome', 'pov', 'femdom', 'christmas',\n",
    "    'girlfriend', 'cosplay', 'facesitting', 'massage', 'deepthroat', 'strapon', 'cheating', 'humping', 'cum in pussy',\n",
    "    'ass licking', 'creampie', 'ball licking', 'spanking', 'orgasm', 'double penetration', 'couple', 'family',\n",
    "    'anal gape', 'bbc', 'party', 'schoolgirl', 'fisting', 'missionary', 'squirting', 'pissing', 'gangbang', 'old man',\n",
    "    'ffm', 'cuckold', 'seduction', 'tribbing', 'orgy', 'flexible', 'cfnm', 'footjob', 'blowbang', 'pegging', 'pregnant',\n",
    "    'swingers', 'gloryhole', 'caught', 'college', 'yoga', 'casting', 'stripper', 'step sister', 'voyeur', 'mmf',\n",
    "    'bukkake', 'gyno', 'small cock', 'babysitter', 'cheerleader', 'cum swapping', 'bisexual', 'goth', 'braces', 'pawg',\n",
    "    'pretty', 'pigtails', 'emo', 'latex', 'babe', 'step brother', 'twink', 'shemale', 'ballerina', 'twins', 'pornstar',\n",
    "    'model', 'latex', 'emo', 'latex', 'babe', 'leather', 'pigtails', 'halloween', 'wedding',\n",
    "    'tall', 'doctor', 'vintage', 'rough sex', 'sex', 'gym', 'sandals', 'big woman',\n",
    "}"
   ],
   "id": "6e7ad93db80bdceb",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:49.553779Z",
     "start_time": "2024-06-12T11:26:39.923455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_positives(row):\n",
    "    labels = row.labels\n",
    "    labels = [L.lower() for L in labels]\n",
    "    for L in labels:\n",
    "        if L in mandatory_columns:\n",
    "            return labels\n",
    "\n",
    "\n",
    "def filter_negatives(row):\n",
    "    labels = row.labels\n",
    "    labels = [L.lower() for L in labels]\n",
    "\n",
    "    for L in labels:\n",
    "        if L in negative_columns:\n",
    "            return None\n",
    "        if L in tags_to_drop:\n",
    "            return None\n",
    "    return labels\n",
    "\n",
    "\n",
    "ai_df = df_not_mapped.copy()\n",
    "ai_df['labels'] = ai_df.apply(filter_positives, axis=1)\n",
    "ai_df = ai_df[ai_df['labels'].notnull()]\n",
    "print(ai_df.shape)\n",
    "\n",
    "ai_df['labels'] = ai_df.apply(filter_negatives, axis=1)\n",
    "ai_df = ai_df[ai_df['labels'].notnull()]\n",
    "ai_df.reset_index(inplace=True, drop=True)\n",
    "print(ai_df.shape)"
   ],
   "id": "204714d7afc63961",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411065, 7)\n",
      "(37734, 7)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:49.744583Z",
     "start_time": "2024-06-12T11:26:49.554543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ai_gen_gallery_mapping(row):\n",
    "    labels = row.labels\n",
    "\n",
    "    out = []\n",
    "    for L in labels:\n",
    "        _fetched = AI_GEN_GALLERIES_MAP.get(L, None)\n",
    "        if _fetched is remove_tag:\n",
    "            continue\n",
    "        elif _fetched is remove_gallery:\n",
    "            return None\n",
    "        elif isinstance(_fetched, list):\n",
    "            out.extend(_fetched)\n",
    "        elif _fetched is keep_tag:\n",
    "            out.append(L.lower())\n",
    "\n",
    "    return list(set(out))\n",
    "\n",
    "\n",
    "ai_df['labels'] = ai_df.apply(ai_gen_gallery_mapping, axis=1)\n",
    "ai_df = ai_df[ai_df['labels'].notnull()]\n",
    "ai_df.drop(\n",
    "    ['height', 'width'], axis=1, inplace=True\n",
    ")\n",
    "ai_df.shape"
   ],
   "id": "ff94b991cd6706b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37734, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:49.763157Z",
     "start_time": "2024-06-12T11:26:49.745295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_df = add_file_path_column(ai_df)\n",
    "ai_df.shape"
   ],
   "id": "53d1d2146f75a01d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37734, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:50.213012Z",
     "start_time": "2024-06-12T11:26:50.031248Z"
    }
   },
   "cell_type": "code",
   "source": "ai_df.to_csv(\"datasets/ai_gen.csv\")",
   "id": "9e068ea55d729ed3",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset inspection",
   "id": "6b22f048edb73740"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:26:51.516571Z",
     "start_time": "2024-06-12T11:26:50.214009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ai_gen = pd.read_csv('datasets/ai_gen.csv', index_col=0)\n",
    "small_one_hot = pd.read_csv('datasets/small_one_hot.csv', index_col=0)\n",
    "medium_one_hot = pd.read_csv('datasets/medium_one_hot.csv', index_col=0)"
   ],
   "id": "6a889452ea3eb7d",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:32:06.562888Z",
     "start_time": "2024-06-12T11:31:06.634800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_paths = []\n",
    "missing = 0\n",
    "\n",
    "for file_path in medium_one_hot['file_path'].to_list():\n",
    "    file_path = Path(file_path)\n",
    "    json_path = SRC_DIR / file_path.parent / 'cropped' / (file_path.stem + '.json')\n",
    "    if not json_path.exists():\n",
    "        missing_paths.append((SRC_DIR / file_path).as_posix())\n",
    "        missing += 1"
   ],
   "id": "4e9f282d8a496a20",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:32:06.613298Z",
     "start_time": "2024-06-12T11:32:06.564794Z"
    }
   },
   "cell_type": "code",
   "source": "missing_df = pd.DataFrame(missing_paths, columns=['file_path'])",
   "id": "561c7fafb8219a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42108"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T12:12:04.826061Z",
     "start_time": "2024-06-12T12:12:04.710435Z"
    }
   },
   "cell_type": "code",
   "source": "missing_df.to_csv('datasets/missing_paths.csv')",
   "id": "e0f3cc1065c80f71",
   "outputs": [],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
