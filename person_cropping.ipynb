{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-16T20:49:48.990586Z",
     "start_time": "2024-06-16T20:49:47.209332Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:49:49.018697Z",
     "start_time": "2024-06-16T20:49:48.991513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from threading import Lock\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = YOLO(\"yolov8n.pt\", verbose = False).to(device)\n",
    "model_lock = Lock() "
   ],
   "id": "b3b248dfdc2de90",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:49:49.024409Z",
     "start_time": "2024-06-16T20:49:49.019858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to detect persons in a single image\n",
    "def detect_persons(image, model):\n",
    "    with model_lock:\n",
    "        results = model(image, verbose = False)\n",
    "        boxes = np.array([box.xyxy.cpu().numpy() for box in results[0].boxes if box.cls.cpu().numpy()[0] == 0]).reshape(-1, 4)\n",
    "        return boxes\n",
    "\n",
    "# Function to create a single bounding box that encapsulates all detected persons\n",
    "def get_combined_bounding_box(boxes):\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "    x_min = np.min(boxes[:, 0])\n",
    "    y_min = np.min(boxes[:, 1])\n",
    "    x_max = np.max(boxes[:, 2])\n",
    "    y_max = np.max(boxes[:, 3])\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "# Function to crop persons from an image\n",
    "def crop_persons(image, combined_box):\n",
    "    if combined_box is None:\n",
    "        return None  # Return None if no person detected\n",
    "    x1, y1, x2, y2 = combined_box\n",
    "    crop = image.crop((x1, y1, x2, y2))\n",
    "    return crop\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(image_path, output_dir, model, progress_bar, target_size=(640, 640)):\n",
    "    image = Image.open(image_path)\n",
    "    resized_image = image.resize(target_size)\n",
    "    image_np = np.array(resized_image)\n",
    "    \n",
    "    boxes = detect_persons(image_np, model)\n",
    "    combined_box = get_combined_bounding_box(boxes)\n",
    "    crop = crop_persons(image, combined_box)\n",
    "    \n",
    "    if crop is not None:\n",
    "        output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "        crop.save(output_path)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Main pipeline function\n",
    "def person_cropping_pipeline(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_paths = [os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    with tqdm(total=len(image_paths)) as progress_bar:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for image_path in image_paths:\n",
    "                executor.submit(process_image, image_path, output_dir, model, progress_bar)"
   ],
   "id": "18e3cdb8f942af8c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:51:04.729249Z",
     "start_time": "2024-06-16T20:51:04.723118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import SRC_DIR\n",
    "\n",
    "input_dir = SRC_DIR\n",
    "output_dir = SRC_DIR.as_posix().replace(\"images\", \"cropped_images\")\n",
    "person_cropping_pipeline(input_dir, output_dir)"
   ],
   "id": "77f557e404f97975",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('images'), 'cropped_images')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "85b3589cc7dd6989",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
