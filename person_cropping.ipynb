{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-16T20:24:28.657Z",
     "start_time": "2024-06-16T20:24:28.654088Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:24:29.470082Z",
     "start_time": "2024-06-16T20:24:29.430592Z"
    }
   },
   "cell_type": "code",
   "source": "model = YOLO(\"yolov8n.pt\")",
   "id": "b3b248dfdc2de90",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T20:24:29.860890Z",
     "start_time": "2024-06-16T20:24:29.855790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to detect persons in a batch of images\n",
    "def detect_persons(images):\n",
    "    results = model(images, verbose=False)\n",
    "    batch_boxes = []\n",
    "    for result in results:\n",
    "        boxes = np.array([box.xyxy.numpy() for box in result.boxes if box.cls.numpy()[0] == 0]).reshape(-1, 4)\n",
    "        batch_boxes.append(boxes)\n",
    "    return batch_boxes\n",
    "\n",
    "# Function to create a single bounding box that encapsulates all detected persons\n",
    "def get_combined_bounding_box(boxes):\n",
    "    if len(boxes) == 0:\n",
    "        return None\n",
    "    x_min = np.min(boxes[:, 0])\n",
    "    y_min = np.min(boxes[:, 1])\n",
    "    x_max = np.max(boxes[:, 2])\n",
    "    y_max = np.max(boxes[:, 3])\n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "# Function to crop persons from an image\n",
    "def crop_persons(image, combined_box):\n",
    "    if combined_box is None:\n",
    "        return None  # Return None if no person detected\n",
    "    x1, y1, x2, y2 = combined_box\n",
    "    crop = image.crop((x1, y1, x2, y2))\n",
    "    return crop\n",
    "\n",
    "# Function to process a batch of images\n",
    "def process_batch(image_paths, output_dir, progress_bar):\n",
    "    images = [Image.open(image_path) for image_path in image_paths]\n",
    "    images_np = [np.array(image) for image in images]\n",
    "    batch_boxes = detect_persons(images_np)\n",
    "    \n",
    "    for image_path, image, boxes in zip(image_paths, images, batch_boxes):\n",
    "        combined_box = get_combined_bounding_box(boxes)\n",
    "        crop = crop_persons(image, combined_box)\n",
    "        if crop is not None:\n",
    "            output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "            crop.save(output_path)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "# Main pipeline function\n",
    "def person_cropping_pipeline(input_dir, output_dir, batch_size=4):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    image_paths = [os.path.join(input_dir, fname) for fname in os.listdir(input_dir) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    with tqdm(total=len(image_paths)) as progress_bar:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for i in range(0, len(image_paths), batch_size):\n",
    "                batch = image_paths[i:i + batch_size]\n",
    "                executor.submit(process_batch, batch, output_dir, progress_bar)"
   ],
   "id": "18e3cdb8f942af8c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-16T20:24:30.978145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dir = './images'\n",
    "output_dir = './cropped_images'\n",
    "person_cropping_pipeline(input_dir, output_dir)"
   ],
   "id": "77f557e404f97975",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 57/411677 [00:11<36:03:12,  3.17it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "85b3589cc7dd6989",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
